{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9515958,"sourceType":"datasetVersion","datasetId":5793177},{"sourceId":12305816,"sourceType":"datasetVersion","datasetId":7756586},{"sourceId":158171,"sourceType":"modelInstanceVersion","modelInstanceId":134422,"modelId":157175}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile model_runner.py\nimport json\nimport os, sys\nimport bz2\nimport pickle\nimport numpy as np\nfrom tqdm import tqdm\n\ndef indices_required_for_merges(keep_indices, vocab, merges):\n    merges_lookup = {}\n    for m in merges:\n        a, b = m.split(' ') if isinstance(m, str) else m\n        key = vocab[f'{a}{b}']\n        if key not in merges_lookup: merges_lookup[key] = set()\n        merges_lookup[key].add(vocab[a])\n        merges_lookup[key].add(vocab[b])\n    to_process = list(keep_indices)\n    while len(to_process):\n        for w in merges_lookup.get(to_process.pop(), []):\n            if w not in keep_indices:\n                keep_indices[w] = None\n                to_process.append(w)\n    return keep_indices\n\ndef remove_unused_merges(merges, vocab):\n    return [f'{a} {b}' for a, b in [m.split(' ') if isinstance(m, str) else m for m in merges] if all(w in vocab for w in [a, b, a + b])]\n\ndef map_special_tokens(data, mapping=None):\n    tokens = set()\n    if isinstance(data, dict):\n        special = data.get('special_tokens')\n        if special is not None:\n            for v in special.values():\n                tokens.update(v['ids'])\n                if mapping is not None:\n                    v['ids'] = [mapping.get(i) for i in v['ids'] if i in mapping]\n    for v in (data.values() if isinstance(data, dict) else data if isinstance(data, list) else []):\n        tokens.update(map_special_tokens(v, mapping))\n    return tokens\n\ndef remove_tokenizer_normalizer(tokenizer):\n    from tokenizers import Tokenizer\n    assert tokenizer.is_fast\n    tokenizer_json = json.loads(tokenizer._tokenizer.to_str())\n    if tokenizer_json.get('normalizer') is not None:\n        tokenizer_json['normalizer'] = None\n        tokenizer._tokenizer = Tokenizer.from_str(json.dumps(tokenizer_json))\n\ndef shrink_tokenizer_vocab(tokenizer, keep_indices, keep_special_tokens, keep_token_order):\n    from tokenizers import Tokenizer\n    assert tokenizer.is_fast\n    tokenizer_json = json.loads(tokenizer._tokenizer.to_str())\n    assert tokenizer_json['model']['type'] == \"BPE\"\n    if keep_special_tokens:\n        keep_indices.update({k: None for k in tokenizer.all_special_ids})\n        keep_indices.update({k: None for k in map_special_tokens(tokenizer_json.get('post_processor'))})\n    keep_indices = indices_required_for_merges(keep_indices, tokenizer_json['model']['vocab'], tokenizer_json['model']['merges'])\n    if keep_token_order: keep_indices = sorted(keep_indices)\n    mapping = {old: new for new, old in enumerate(keep_indices)}\n    tokenizer_json['model']['vocab'] = {k: mapping[v] for k, v in tokenizer_json['model']['vocab'].items() if v in mapping}\n    tokenizer_json['model']['merges'] = remove_unused_merges(tokenizer_json['model']['merges'], tokenizer_json['model']['vocab'])\n    special_tokens_order = [t['id'] for t in tokenizer_json['added_tokens']]\n    assert special_tokens_order==sorted(special_tokens_order)\n    tokenizer_json['added_tokens'] = sorted([{**t, 'id': mapping[t['id']]} for t in tokenizer_json['added_tokens'] if t['id'] in mapping], key=lambda t: t['id'])\n    map_special_tokens(tokenizer_json.get('post_processor'), mapping)\n    tokenizer._tokenizer = Tokenizer.from_str(json.dumps(tokenizer_json))\n    return mapping, keep_indices\n\ndef shrink_model_embeddings(model, keep_indices, mapping):\n    import torch\n    with torch.no_grad():\n        row_select = torch.tensor(list(keep_indices))\n        new_embed_t = torch.index_select(model.get_input_embeddings().weight.data, 0, row_select.to(model.get_input_embeddings().weight.data.device))\n        new_lm_head = torch.index_select(model.get_output_embeddings().weight.data, 0, row_select.to(model.get_output_embeddings().weight.data.device))\n        model.resize_token_embeddings(len(keep_indices))\n        model.get_input_embeddings().weight.data[:] = new_embed_t\n        model.get_output_embeddings().weight.data[:] = new_lm_head\n        for config in [model.config, model.generation_config]:\n            for k, v in list(config.to_dict().items()):\n                if k.endswith('token_id'):\n                    setattr(config, k, [mapping.get(t) for t in v] if isinstance(v, list) else mapping.get(v))\n\ndef shrink_embeddings(model, tokenizer, corpus=None, keep_token_ids=[], keep_tokens=[], remove_token_ids=[], keep_model_tokens=True, keep_special_tokens=True, keep_normalizer=False, keep_token_order=True):\n    if not keep_normalizer: remove_tokenizer_normalizer(tokenizer)\n    from collections import OrderedDict  # use as OrderedSet\n    keep_indices = OrderedDict()\n    keep_indices.update({k: None for k in keep_token_ids})\n    keep_indices.update({tokenizer.vocab[t]: None for t in keep_tokens})\n    if corpus is not None: keep_indices.update({k: None for k in tokenizer(corpus)['input_ids']})\n    if keep_model_tokens:\n        for config in [model.config, model.generation_config]:\n            for k, v in config.to_dict().items():\n                if k.endswith('token_id'):\n                    keep_indices.update({k: None for k in (v if isinstance(v, list) else [v])})\n    keep_indices.pop(None, None)\n    for idx in remove_token_ids: keep_indices.pop(idx, None)\n    mapping, keep_indices = shrink_tokenizer_vocab(tokenizer, keep_indices, keep_special_tokens, keep_token_order)\n    shrink_model_embeddings(model, keep_indices, mapping=mapping)\n    return mapping\n\ndef fix_dtypes(model, fix_weights=True, fix_quant_states=True):\n    import torch\n    for module in model.modules():\n        weight = getattr(module, 'weight', None)\n        if weight is not None:\n            if torch.is_floating_point(weight):\n                if fix_weights and weight.dtype!=model.dtype:\n                    module.to(model.dtype)\n            else:\n                qs = getattr(weight, 'quant_state', None)\n                if qs is not None:\n                    if fix_quant_states and qs.dtype!=model.dtype:\n                        qs.dtype = model.dtype\n    return model\n\ndef merge_peft_into_base(model):\n    print('*** Merge peft model into base model...')\n    assert is_peft_model(model)\n    return fix_dtypes(model.merge_and_unload())\n\ndef save_model(store_path, model=None, tokenizer=None, merge=False):\n    if merge: model = merge_peft_into_base(model)\n    if store_path is not None:\n        assert model is not None or tokenizer is not None\n        print(f\"*** Saving{' merged' if merge else ''} model/tokenizer to '{store_path}'...\")\n        if model is not None: model.save_pretrained(store_path)\n        if tokenizer is not None:\n            tokenizer.save_pretrained(store_path)\n            to_delete = os.path.join(store_path, 'tokenizer.model')\n            if os.path.isfile(to_delete): os.remove(to_delete)\n    return model\n\ndef is_unsloth_model(model):\n    return model.model_tags is not None and 'unsloth' in model.model_tags\n\ndef is_peft_model(model):\n    return hasattr(model, 'peft_type')\n\ndef download_model(repo_id, store_path, get_name=lambda n: os.path.join(n.replace('/', '--'), 'transformers', 'default', '1')):\n    import os\n    if os.path.exists(repo_id): return repo_id\n    model_path = os.path.join(store_path, get_name(repo_id))\n    if not os.path.exists(model_path):\n        from huggingface_hub import snapshot_download\n        download_path = snapshot_download(repo_id=repo_id)\n        os.makedirs(os.path.split(model_path)[0], exist_ok=True)\n        os.symlink(download_path, model_path, target_is_directory=True)\n    return model_path\n\ndef get_and_fix_peft_weights(store):\n    print(f\"*** Load peft state_dict from '{store}'...\")\n    from peft import load_peft_weights\n    state_dict = load_peft_weights(store)\n    for k in list(state_dict.keys()):\n        if 'modules_to_save' in k:\n            del state_dict[k]\n            original_module_key = k.replace('.modules_to_save.', '.original_module.')\n            if original_module_key in state_dict: del state_dict[original_module_key]\n            assert k.replace('.modules_to_save.', '.') in state_dict\n    return state_dict\n\ndef set_peft_weights(model, state_dict):\n    print(f\"*** Set model state_dict...\")\n    from peft import set_peft_model_state_dict\n    res = set_peft_model_state_dict(model, state_dict)\n    assert not res.unexpected_keys\n\ndef load_peft_state(model, store):\n    set_peft_weights(model, get_and_fix_peft_weights(store))\n\ndef prepare_model(model, mode, tokenizer=None, formatter=None, shrink_embedding=False, dequantize=False, peft=[], local_files_only=False, add_special_tokens={}, set_pad_token=None, keep_tokens=[], keep_normalizer=None, peft_trainable=True, device_map=None, tf_grad_cp=True, tf_use_fa2=True, **kwargs):\n    if isinstance(model, str):\n        assert tokenizer is None\n        print(f\"*** Load base model and tokenizer from '{model}'...\")\n        if mode=='unsloth_4bit':\n            assert device_map is None, 'unsupported'\n            from unsloth import FastLanguageModel\n            model, tokenizer = FastLanguageModel.from_pretrained(model_name=model, dtype=None, load_in_4bit=True, local_files_only=local_files_only, **kwargs)\n        elif mode in ['transformers', 'transformers_bf16', 'transformers_4bit', 'transformers_bf16_4bit', 'tokenizer_only']:\n            import torch\n            model_load_args = {}\n            if device_map is not None: model_load_args['device_map'] = device_map\n            if tf_use_fa2: model_load_args['attn_implementation'] = 'flash_attention_2'\n            if mode in ['transformers_bf16', 'transformers_bf16_4bit']: model_load_args['torch_dtype'] = torch.bfloat16\n            elif mode in ['transformers_4bit', 'transformers_bf16_4bit']:\n                from transformers import BitsAndBytesConfig\n                nf4_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16)\n                model_load_args['quantization_config'] = nf4_config\n            from transformers import AutoTokenizer, AutoModelForCausalLM\n            tokenizer = AutoTokenizer.from_pretrained(model, local_files_only=local_files_only, **kwargs)\n            model = AutoModelForCausalLM.from_pretrained(model, **model_load_args) if mode!='tokenizer_only' else None\n            if tf_grad_cp and model is not None: model.gradient_checkpointing_enable()\n        else: raise NotImplementedError('Unknown mode.')\n    if add_special_tokens: tokenizer.add_special_tokens(add_special_tokens)\n    if set_pad_token is not None: tokenizer.pad_token = set_pad_token\n    if formatter is not None and not hasattr(formatter, 'corpus'):\n        formatter = formatter(tokenizer=tokenizer)\n    if (shrink_embedding<len(tokenizer.vocab) if type(shrink_embedding)==int else shrink_embedding) or keep_normalizer is False:\n        print('*** Shrink embedding...')\n        embedding_size_before_shrink = len(tokenizer.vocab)\n        mapping = shrink_embeddings(model, tokenizer, formatter.get_corpus(), keep_tokens=keep_tokens, keep_normalizer=keep_normalizer)\n        print(f'*** -> Reduced embedding size from {embedding_size_before_shrink} to {len(mapping)} words.')\n    if dequantize:\n        print(f'*** Dequantize model...')\n        model = model.dequantize()\n    if len(peft):\n        peft_trained = True if is_peft_model(model) else None\n        for i, m in enumerate(peft):\n            if peft_trained is True: model, peft_trained = merge_peft_into_base(model), None\n            if isinstance(m, str):\n                if peft_trained is False:\n                    _, peft_trained = load_peft_state(model, m), True\n                else:\n                    print(f\"*** Load peft model from '{m}'...\")\n                    # be careful when using unsloth - using PeftModel to load the model will not apply unsloth optimizations\n                    from peft import PeftModel\n                    model, peft_trained = PeftModel.from_pretrained(model, m, trainable=peft_trainable), True\n            else:\n                assert peft_trained is None\n                if isinstance(m, dict):\n                    print('*** Create new peft model...')\n                    if is_unsloth_model(model):\n                        from unsloth import FastLanguageModel\n                        my_get_peft_model = FastLanguageModel.get_peft_model\n                    else:\n                        from peft import LoraConfig, get_peft_model\n                        my_get_peft_model = lambda model, **kwargs: get_peft_model(model, LoraConfig(**kwargs))\n                    model, peft_trained = my_get_peft_model(model, **m), False\n                else: assert m is None\n    return model, tokenizer, formatter\n\ndef training_run(model, formatter, dataset, train_args, max_seq_length, merge=False, store=None, packing=False, grad_acc_fix=False, optimizers=None):\n    assert merge is False, \"merge after training does not seen to work (at least with unsloth, saved merged model will cointain the untrained weights!)\"\n    import torch\n    from datasets import Dataset\n    add_train_args = {}\n    if is_unsloth_model(model):\n        from unsloth import FastLanguageModel\n        from unsloth import UnslothTrainer as Trainer\n        from unsloth import UnslothTrainingArguments as TrainingArguments\n        from unsloth import is_bfloat16_supported\n        FastLanguageModel.for_training(model)\n        add_train_args.update(fp16=not is_bfloat16_supported(), bf16=is_bfloat16_supported())\n    else:\n        from trl import SFTConfig as TrainingArguments\n        from trl import SFTTrainer as Trainer\n        model.train()\n        add_train_args.update(bf16=True)\n\n    formatter.tokenizer.padding_side = 'right'\n    if is_unsloth_model(model):\n        for convert_to_float in [model.get_input_embeddings(), model.get_output_embeddings()]:\n            if convert_to_float.weight.dtype!=torch.float32: convert_to_float.to(torch.float32)\n\n    add_args = {}\n    if optimizers is not None: add_args['optimizers'] = optimizers\n\n    trainer = Trainer(\n        model=model,\n        tokenizer=formatter.tokenizer,\n        data_collator=formatter.get_data_collator(),\n        train_dataset=Dataset.from_list(dataset.as_list(formatter)),\n        dataset_text_field=\"text\",\n        max_seq_length=max_seq_length,\n        dataset_num_proc=None,\n        packing=packing,  # Can make training 5x faster for short sequences.\n        **add_args,\n        args=TrainingArguments(\n            **add_train_args,\n            **train_args\n        ),\n    )\n\n    print('*** Start training run...')\n    if grad_acc_fix and is_unsloth_model(model):\n        from unsloth import unsloth_train\n        trainer_stats = unsloth_train(trainer)\n    else:\n        if is_unsloth_model(model) and train_args['gradient_accumulation_steps']>1: print('*** WARNING: using faulty unsloth gradient accumulation')\n        trainer_stats = trainer.train()\n    try: print(f'*** -> Training took {trainer_stats.metrics[\"train_runtime\"]} seconds.')\n    except: pass\n    if store is not None: save_model(store, model, formatter.tokenizer, merge=merge)\n    return model, trainer_stats\n\ndef inference_load(store, keys=True, result_dict=None, always_read_from_file=False):\n    if result_dict is None: result_dict = {}\n    if store is not None:\n        if keys is True: keys = os.listdir(store)\n        for key in keys:\n            if always_read_from_file or key not in result_dict:\n                try:\n                    with bz2.BZ2File(os.path.join(store, key)) as f: result_dict[key] = pickle.load(f)\n                except: continue\n    return result_dict\n\ndef inference_save(store, key, outputs):\n    if store is not None:\n        os.makedirs(store, exist_ok=True)\n        with bz2.BZ2File(os.path.join(store, key), 'w') as f: pickle.dump(outputs, f)\n\nclass Decoder(object):\n    def __init__(self, formatter, dataset, n_guesses, max_outputs=None, frac_score=False, quiet=False, name='', additional_decoders=None, prob_baseline=None):\n        self.formatter = formatter\n        self.dataset = dataset\n        self.n_guesses = n_guesses\n        self.decoded_results = {}\n        self.correct_solutions = {}\n        self.keys_lim = set()\n        self.keys_all = set()\n        self.mult_cnt = {}\n        self.keys_cnt = {}\n        self.frac_score = frac_score\n        self.max_outputs = max_outputs\n        self.quiet = quiet\n        self.input_len = [{} if formatter is not None and formatter.tokenizer is None else ds.get_lengths(formatter, name='input') for ds in [dataset, dataset.mod(np.transpose, keep_key=True)]]\n        self.reply_len = [{} if formatter is not None and formatter.tokenizer is None else ds.get_lengths(formatter, name='reply') for ds in [dataset, dataset.mod(np.transpose, keep_key=True)]]\n        self.additional_decoders = additional_decoders\n        self.name = name\n        self.prob_tracker = {}\n        self.prob_tracker_best = {}\n        self.prob_baseline = prob_baseline\n\n    def score(self, *to_score):\n        scores = [(sum(1/self.mult_cnt[k.split('_')[0]] for k in s) if self.frac_score else len(s)) for s in to_score]\n        score_cnt = len(self.mult_cnt if self.frac_score else self.keys_cnt)\n        return scores, score_cnt\n\n    def from_store(self, store, **kwargs):\n        for key, outputs in inference_load(store).items():\n            self.process(key, outputs, **kwargs)\n        return self\n\n    def score_fmt(self, v):\n        return f'{v:5.1f}' if self.frac_score else f'{v:3}'\n\n    def process_single_output(self, key, output_len, decoded, print_func=print, len_info=None, device_info=None):\n        import numpy as np\n        inv_mod = {k: v if k.endswith('val') else self.dataset.invert_mod(v, key, inv_perm=(k.startswith('output') or k.startswith('score_all'))) for k, v in decoded.items()}\n        base_key = key.split('.')[0]\n        self.decoded_results[base_key] = self.decoded_results.get(base_key, {})\n        self.decoded_results[base_key][key] = inv_mod\n        output = inv_mod.get('output')\n        score = inv_mod.get('score')\n\n        # quick scoring\n        self.keys_cnt[base_key] = self.keys_cnt.get(base_key, 0) + 1\n        mult_key, mult_sub = (base_key.split('_') + ['0'])[:2]\n        self.mult_cnt[mult_key] = max(self.mult_cnt.get(mult_key, 0), int(mult_sub) + 1)\n        if len(self.dataset.replies):\n            correct_solution = self.dataset.replies.get(base_key)\n            if correct_solution is not None:\n                correct_solution = correct_solution[0]\n                self.correct_solutions[base_key] = correct_solution\n                is_correct = correct_solution is not None and np.array_equal(correct_solution, output)\n                if is_correct:\n                    self.keys_all.add(base_key)\n                    if self.keys_cnt[base_key] <= self.n_guesses: self.keys_lim.add(base_key)\n            corr_str = 'cant_decode' if output is None else 'sol_unknown' if correct_solution is None else 'ALL_CORRECT' if is_correct else 'bad_xy_size' if np.shape(correct_solution)!=np.shape(output) else 'bad_content'\n            (score_lim, score_all), score_cnt = self.score(self.keys_lim, self.keys_all)\n\n            tp_arr = (key.count('transpose') + key.count('rot90')) % 2\n            msc = None if score is None else np.sum(score)\n            fsc = inv_mod.get('score_val')\n            if output is not None and fsc is not None:\n                pt = self.prob_tracker[base_key] = self.prob_tracker.get(base_key, {})\n                hash = tuple(map(tuple, output))\n                prob = pt[hash] = pt.get(hash, 0) + (np.exp(fsc) if self.prob_baseline is None else fsc - np.log(self.prob_baseline))\n                current_best = self.prob_tracker_best.get(base_key)\n                if current_best is None or current_best[0]<prob:\n                    self.prob_tracker_best[base_key] = (prob, output)\n            fmt_name = f'{self.name}: ' if self.name else ''\n            msc_print = f'{min(-msc, 9.99999):7.5f}' if msc is not None else 'unknown'\n            fsc_print = f'{min(-fsc, 9.99999):7.5f}' if fsc is not None else 'unknown'\n            if not self.quiet: print_func(f\" {fmt_name}acc: {self.score_fmt(score_lim)}/{score_cnt:3}={min(score_lim/score_cnt, 0.999):5.1%} (2-guess), {self.score_fmt(score_all)}/{score_cnt:3}={min(score_all/score_cnt, 0.999):5.1%} (any);{f' {device_info}' if device_info else ''} tok:{self.input_len[tp_arr].get(base_key, '?'):>4}+{self.reply_len[tp_arr].get(base_key, '?'):>3}>{'n/a' if output_len is None else output_len:>3} {corr_str}:{msc_print}|{fsc_print} [{key}]\")\n\n    def get_current_best(self, base_key):\n        current_best = self.prob_tracker_best.get(base_key)\n        return None if current_best is None else current_best[1]\n\n    def process_single_decode(self, key, de_tokenized, print_func=print, **kwargs):\n        if len(de_tokenized)==3 and not isinstance(de_tokenized[1], float):  # for backwards compatibility\n            output_len, *data = de_tokenized\n            score_val = None\n        else: output_len, score_val, *data = de_tokenized\n        if self.formatter is None:\n            assert len(data) == 1\n            decoded = [data[0]]\n        else: decoded = self.formatter.decode_to_array(*data)\n        #if len(decoded)==2:\n        #    same = np.array_equal(decoded[0].get('output'), decoded[1].get('output'))\n        #    print_func(f\"is_identical: {same}\")\n        #    if not same: for i in range(2): print_func(str(decoded[i].get('output')))\n        for d in decoded: d['score_val'] = score_val\n        for i, dec in enumerate(decoded):\n            if i==0: self.process_single_output(key, output_len, dec, print_func=print_func, **kwargs)\n            elif self.additional_decoders:\n                if i-1<len(self.additional_decoders): self.additional_decoders[i-1].process_single_output(key, output_len, dec, print_func=print_func, **kwargs)\n                else: print_func(f'{key} no decoder available for output #{i}')\n            else: self.process_single_output(f'{key}.fix{i}', output_len, dec, print_func=print_func, **kwargs)\n\n    def process(self, key, de_tokenized, **kwargs):\n        for i, d in enumerate(de_tokenized):\n            if self.max_outputs is None or i<=self.max_outputs:\n                self.process_single_decode(f'{key}.out{i}', d, **kwargs)\n\n    def get_unsolved_keys(self):\n        unsolved = []\n        for base_key, reply in self.dataset.replies.items():\n            if not any(np.array_equal(reply[0], s.get('output')) for s in self.decoded_results.get(base_key, {}).values()):\n                unsolved.append(base_key)\n        return unsolved\n\n    def run_selection_algo(self, selection_algorithm):\n        return {bk: (selection_algorithm({k: g for k, g in v.items() if g.get('output') is not None}) if any(g.get('output') is not None for g in v.values()) else []) for bk, v in self.decoded_results.items()}\n\n    def benchmark_selection_algos(self, selection_algorithms, skip_failed=True):\n        import numpy as np\n        results = {}\n        print('*** Benchmark selection algorithms...')\n        for selection_algorithm in selection_algorithms:\n            name = selection_algorithm.__name__\n            try:\n                selected = self.run_selection_algo(selection_algorithm)\n                if self.formatter is not None:\n                    for sols in selected.values():\n                        for s in sols:\n                            assert self.formatter.is_valid_solution(s), f'found invalid solutions {s}'\n                correct_keys = {k for k, v in selected.items() if self.correct_solutions.get(k) is not None and any(np.array_equal(guess, self.correct_solutions[k]) for guess in v[:self.n_guesses])}\n                (score,), score_cnt = self.score(correct_keys)\n                results[name] = score\n                print(f\" acc: {score:5.1f}/{score_cnt:3}={score/score_cnt:6.2%} ('{name}')\")\n            except:\n                print(f\" {'execution failed':>21} ('{name}')\")\n                if not skip_failed: raise\n        return results\n\n    def calc_augmented_scores(self, model, base_keys=None, store=None, seed=0, max_len=None, make_unique=True, quiet=False, **kwargs):\n        if base_keys is None: base_keys = list(self.decoded_results.keys())\n        if store is not None: store = f'{store}_new'  # new format is not backwards compatible, so use new folder\n        for bk in (base_keys if quiet else tqdm(base_keys, desc='calculate augmented scores', file=sys.stdout)):\n            res = self.decoded_results.get(bk, {})\n            known_scores = {}\n            for k, v in sorted(res.items()):\n                if 'output' in v:\n                    k_store = None if store is None else os.path.join(store, k)\n                    id = tuple(map(tuple, v['output']))\n                    if not (make_unique and id in known_scores):\n                        try:\n                            assert k_store is not None\n                            with bz2.BZ2File(k_store) as f: known_scores[id] = pickle.load(f)\n                            if isinstance(known_scores[id], list): known_scores[id] = dict(score_multi=known_scores[id])  # for backwards compatibility\n                            k_store = None\n                        except:\n                            temp_dataset = self.dataset.__class__(\n                                keys=[bk],\n                                queries={bk: self.dataset.queries.get(bk)},\n                                replies={bk: [v['output'].tolist()]},\n                            )\n                            temp_decoder = self.__class__(self.formatter, temp_dataset, n_guesses=self.n_guesses, quiet=True)\n                            temp_dataset = temp_dataset.augment(**kwargs, seed=(seed+hash(k)+hash(id)) % 1024**2, quiet=True)\n                            if max_len is not None: temp_dataset = temp_dataset.cut_to_len(formatter=self.formatter, name='input', max_len=max_len, quiet=True)\n                            for x in temp_dataset.as_list(self.formatter): calc_score(**x, formatter=self.formatter, model=model, decoder=temp_decoder)\n                            known_scores[id] = dict(\n                                score_multi=[np.sum(x['score']) for x in temp_decoder.decoded_results[bk].values()],\n                                score_multi_nl=[x['score_val'] for x in temp_decoder.decoded_results[bk].values()],\n                                score_multi_array=np.array([x['score'] for x in temp_decoder.decoded_results[bk].values()]),\n                                score_multi_array_cum=np.array([x['score_cum'] for x in temp_decoder.decoded_results[bk].values()]),\n                                score_multi_array_all=np.array([x['score_all'] for x in temp_decoder.decoded_results[bk].values()]),\n                                score_multi_array_all_cum=np.array([x['score_all_cum'] for x in temp_decoder.decoded_results[bk].values()]),\n                            )\n                            if k_store is not None:\n                                os.makedirs(store, exist_ok=True)\n                                with bz2.BZ2File(k_store, 'w') as f: pickle.dump(known_scores[id], f)\n                    v.update(known_scores[id])\n\ndef turbo_dfs(model, logits, path, eos_token_id, max_new_tokens, max_score, max_score_greedy, temperature, suppress_tokens, torch, score=0.0, pos=0, cache=None):\n    logits, next_logits = logits[0], (logits[1:] if len(logits)>1 else None)\n    nll = -(logits / temperature).detach().float().log_softmax(-1).cpu().numpy()\n    greedy_index = nll.argmin(-1).item()\n    nll = list(enumerate(nll))\n    if path: nll[0], nll[path[0]], path = nll[path[0]], nll[0], path[1:]  # follow precomputed path first\n    suffixes = []\n    for i, s in nll:\n        next_score = score + s\n        allowed_max_score = max_score_greedy if i==greedy_index else max_score\n        if next_score < allowed_max_score:\n            if i==eos_token_id: next_suffixes = [(next_score, [], [])]\n            elif max_new_tokens>1:\n                if next_logits is None:\n                    if pos<cache[0][0][0].shape[2]: cache[0] = tuple(tuple(c[:, :, :pos] for c in l) for l in cache[0])\n                    next_logits, cache[0] = model(\n                        input_ids= torch.full((1,1), i, device=model.device),\n                        position_ids=torch.full((1,1), pos, device=model.device),\n                        past_key_values=cache[0],\n                    )[:2]\n                    next_logits = next_logits[0]  # unbatch\n                next_suffixes = turbo_dfs(model, logits=next_logits, path=path, eos_token_id=eos_token_id, max_new_tokens=max_new_tokens-1, max_score=max_score, max_score_greedy=allowed_max_score, temperature=temperature, suppress_tokens=suppress_tokens, torch=torch, score=next_score, pos=pos+1, cache=cache)\n            else: next_suffixes = []\n            for suffix in next_suffixes:\n                suffix[1].append(i)\n                suffix[2].append(logits)\n            suffixes.extend(next_suffixes)\n        next_logits = None\n    return suffixes\n\ndef inference_turbo_dfs(model, input_ids, eos_token_id, max_new_tokens, min_prob, min_prob_greedy=1, temperature=1.0, suppress_tokens=[], path=[], attention_mask=None):\n    import torch\n    with torch.no_grad():\n        assert attention_mask is None or attention_mask.all(), 'not implemented'\n        input_ids = torch.as_tensor(input_ids, device=model.device, dtype=int)\n        if input_ids.ndim==2: input_ids = input_ids.squeeze(0)\n        assert input_ids.ndim==1, 'batching not supported'\n        max_score = -np.log(min_prob)\n        max_score_greedy = (-np.log(min_prob_greedy)) if min_prob_greedy>0 else float('inf')  # avoid throwing numpy error\n        max_score_greedy = max(max_score, max_score_greedy)\n        if path is None: path = []\n        if len(path) and path[-1]==eos_token_id: path = path[:-1]\n        with torch.no_grad():\n            full_path = input_ids\n            if len(path): full_path = torch.cat([full_path, torch.as_tensor(path, device=model.device)])\n            logits, cache = model(input_ids=full_path[np.newaxis])[:2]\n            logits = logits[0, len(input_ids)-1:]\n        result = turbo_dfs(model, logits=logits, path=path, eos_token_id=eos_token_id, max_new_tokens=max_new_tokens, max_score=max_score, max_score_greedy=max_score_greedy, temperature=temperature, suppress_tokens=suppress_tokens, torch=torch, score=0.0, pos=len(input_ids), cache=[cache])\n        return sorted([(score_val, np.array(suffix[::-1]), torch.stack(score_arr[::-1]).float().cpu().numpy()) for score_val, suffix, score_arr in result], key=lambda x:x[0])\n\ndef inference_step(tokenized, model, remove_token_type_ids=True, num_beams=1, formatter=None, min_prob=None, current_best=None, **kwargs):\n    import torch\n    if remove_token_type_ids: tokenized.pop('token_type_ids', None)\n    if min_prob is not None:\n        assert num_beams==1\n        gen = inference_turbo_dfs(model, **tokenized.to(model.device), path=current_best, min_prob=min_prob, eos_token_id=formatter.tokenizer.eos_token_id, **kwargs)\n        tokens_out = [[g[1] for g in gen]]\n        scores_out = [[g[2] for g in gen]]\n    elif is_unsloth_model(model) and num_beams > 1:\n        assert False, 'unsloth does not support beam search'\n    else:\n        gen = model.generate(**tokenized.to(model.device), return_dict_in_generate=True, output_logits=True, use_cache=True, **kwargs)\n        tokens_out = gen['sequences'][:, torch.newaxis, tokenized['input_ids'].shape[-1]:].cpu().numpy().copy()\n        scores_out = torch.stack(gen['logits'], axis=-2)[:, torch.newaxis].float().cpu().numpy().copy()\n    return tokens_out, scores_out\n\ndef process_inference_output(key, outputs, formatter, store=None, decoder=None, decoder_args={}):\n    de_tokenized = [formatter.de_tokenize(*output) for output in zip(*outputs)]\n    inference_save(store, key, de_tokenized)\n    if decoder is not None: decoder.process(key, de_tokenized, **decoder_args)\n    return de_tokenized\n\ndef inference_run_v2(model, formatter, dataset, decoder=None, max_new_tokens=None, max_batch_size=1, store=None, result_dict=None, rerun_empty=False, retrain=None, use_turbo=False, group_multi_output=True, **kwargs):\n    import torch\n    assert max_batch_size==1, 'unsupported'\n\n    with torch.no_grad():\n        print('*** Load stored data...')\n        if result_dict is None: result_dict = {}\n        result_dict = inference_load(store, dataset.keys, result_dict)\n        by_base_key = {}\n        needs_rerun = {}\n        base_key_list = []\n        for key in dataset.keys:\n            base_key = key.split('.')[0]\n            if group_multi_output: base_key = base_key.split('_')[0]\n            if base_key not in by_base_key: base_key_list.append(base_key)\n            bk_list = by_base_key[base_key] = by_base_key.get(base_key, [])\n            bk_list.append(key)\n        for base_key, keys in by_base_key.items():\n            for key in keys:\n                de_tokenized = result_dict.get(key)\n                if de_tokenized is None or (rerun_empty and not de_tokenized):\n                    bk_list = needs_rerun[base_key] = needs_rerun.get(base_key, [])\n                    bk_list.append(key)\n                elif decoder is not None: decoder.process(key, de_tokenized)\n\n        formatter.tokenizer.padding_side = 'left'\n        if max_new_tokens is None: max_new_tokens = formatter.max_new_tokens()\n        if is_unsloth_model(model):\n            from unsloth import FastLanguageModel\n            FastLanguageModel.for_inference(model)\n        else: model.eval()\n\n        print('*** Start inference run...')\n    try:\n        with tqdm(base_key_list, file=sys.stdout) as pbar:\n            for base_key in pbar:\n                run_keys = needs_rerun.get(base_key)\n                if run_keys:\n                    if retrain is not None:\n                        retrain_dataset = dataset.keep_key_startswith(base_key)\n                        print(f\"retraining model for key '{base_key}' (retrain_dataset_size={len(retrain_dataset.keys)})\")\n                        retrain(model, retrain_dataset)\n                        if is_unsloth_model(model): FastLanguageModel.for_inference(model)\n                    with torch.no_grad():\n                        for key in run_keys:\n                            input_text = dataset.get(key, formatter)['input']\n                            batch = formatter.tokenizer([input_text], return_tensors='pt')\n                            current_best = decoder.get_current_best(key.split('.')[0]) if use_turbo else None\n                            if current_best is not None:\n                                current_best = dataset.forward_mod(current_best, key)\n                                current_best = formatter.fmt_reply([current_best])\n                                current_best = formatter.tokenizer(input_text+current_best)['input_ids'][batch['input_ids'].shape[-1]:]\n                            batch_out = inference_step(batch, model, formatter=formatter, max_new_tokens=max_new_tokens, current_best=current_best, **kwargs)\n                            outputs = [x[0] for x in batch_out]\n                            result_dict[key] = process_inference_output(key, outputs, formatter, store=store, decoder=decoder, decoder_args=dict(print_func=pbar.write))\n        print('*** Completed inference run.')\n    except KeyboardInterrupt: print('*** Ctrl+C pressed, stopping inference run.')\n    return result_dict\n\nclass Retrainer(object):\n    def __init__(self, n, aug_opts, reload_state_dict=None, **kwargs):\n        self.n = n\n        self.aug_opts = aug_opts\n        self.reload_state_dict = reload_state_dict\n        self.kwargs = kwargs\n\n    def preprocess(self, dataset):\n        ds = [dataset.augment(quiet=True, shfl_keys=True, **self.aug_opts) for _ in range((self.n-1)//dataset.length()+1)]\n        ds = ds[0] if len(ds)==1 else ds[0].append(*ds[1:])\n        ds, _ = ds.split_at_pos(self.n)\n        return ds\n\n    def __call__(self, model, dataset):\n        if self.reload_state_dict is not None: set_peft_weights(model, self.reload_state_dict)\n        assert is_unsloth_model(model), 'not implemented'\n        if is_unsloth_model(model):\n            from unsloth import FastLanguageModel\n            FastLanguageModel.for_training(model)\n        else: model.train()\n        training_run(model, dataset=self.preprocess(dataset), **self.kwargs)\n\ndef calc_score(key, input, reply, formatter, model, store=None, decoder=None, **_):\n    import torch\n    with torch.no_grad():\n        input_len = len(formatter.tokenizer(input)['input_ids'])\n        tokenized = formatter.tokenizer([input+reply], return_tensors='pt')\n        reply_tok = tokenized['input_ids'][0][input_len:].cpu().numpy().copy()\n        reply_log = model.forward(**tokenized.to(model.device))['logits'][0, input_len-1: -1].float().cpu().numpy().copy()\n        process_inference_output(key, (reply_tok[torch.newaxis], reply_log[torch.newaxis]), formatter, store=store, decoder=decoder)\n\ndef mem_info(gpu_id=0):\n    import torch\n    try:\n        gpu_stats = torch.cuda.get_device_properties(gpu_id)\n        usage = torch.cuda.max_memory_reserved() / 1024**3\n        avail = gpu_stats.total_memory / 1024**3\n        print(f\"*** GPU: {gpu_stats.name}, used {usage:.3} / {avail:.3} GB.\")\n    except: print('*** Exception occured when getting memory stats.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T19:55:53.222267Z","iopub.execute_input":"2025-06-27T19:55:53.222614Z","iopub.status.idle":"2025-06-27T19:55:53.247224Z","shell.execute_reply.started":"2025-06-27T19:55:53.222585Z","shell.execute_reply":"2025-06-27T19:55:53.246254Z"}},"outputs":[{"name":"stdout","text":"Overwriting model_runner.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile arc_loader.py\nimport json\nimport numpy as np\nimport hashlib\nimport os, sys\nfrom tqdm import tqdm\nfrom glob import glob\nimport itertools\nimport random\n\ndef cut_at_token(output, token_id):\n    eos_positions = (output==token_id).nonzero()[0]\n    return output[:eos_positions[0]] if len(eos_positions) else output\n\ndef shuffled(data_list):\n    return np.random.permutation(data_list).tolist()\n\ndef permute_mod(a, descriptor, invert=False):\n    permutation = [int(i) for i in descriptor if str(i).isdigit()]\n    assert sorted(permutation)==list(range(10))\n    a = np.asarray(a)\n    if a.ndim==3:\n        if not invert: permutation = np.argsort(permutation)\n        a = a[..., permutation]\n    else:\n        assert a.ndim==2\n        if invert: permutation = np.argsort(permutation)\n        a = np.asarray(permutation)[a]\n    return a\n\ndef permute_rnd_col_(query):\n    permutation = [0]+(1+np.random.permutation(9)).tolist()\n    return 'permute' + ''.join(map(str, permutation))\n\ndef permute_rnd_all_(query):\n    permutation = np.random.permutation(10).tolist()\n    return 'permute' + ''.join(map(str, permutation))\n\ndef permute_cnt_col_(query):\n    elements, frequency = np.unique(np.concatenate([list(range(10))]+[np.array(x['input']).ravel() for x in query['train']]), return_counts=True)\n    permutation = [0]+sorted(np.random.permutation(9)+1, key=lambda i: frequency[i], reverse=True)  # randomness as tie breaker\n    return 'permute' + ''.join(map(str, permutation))\n\ndef permute_cnt_all_(query):\n    elements, frequency = np.unique(np.concatenate([list(range(10))]+[np.array(x['input']).ravel() for x in query['train']]), return_counts=True)\n    permutation = sorted(np.random.permutation(10), key=lambda i: frequency[i], reverse=True)  # randomness as tie breaker\n    return 'permute' + ''.join(map(str, permutation))\n\npermute_rnd_col = (permute_mod, permute_rnd_col_)\npermute_rnd_all = (permute_mod, permute_rnd_all_)\npermute_cnt_col = (permute_mod, permute_cnt_col_)\npermute_cnt_all = (permute_mod, permute_cnt_all_)\npermute_None = (np.copy, None)\n\nclass ArcDataset(object):\n    @staticmethod\n    def forward_mod(a, key, use_perm=True, is_output=True):\n        if a is None: return a\n        for op in key.split('.')[1:]:\n            if op.startswith('I'):\n                if is_output: continue\n                op = op[1:]\n            if   op=='rot90':              a = np.rot90(a)\n            elif op=='transpose':          a = np.swapaxes(a, 0, 1)\n            elif op.startswith('permute'): a = permute_mod(a, op, invert=False) if use_perm else a\n            elif op.startswith('copy'):    a = np.copy(a)\n            elif op.startswith('out'):     a = a\n            elif op.startswith('ex'):      a = a\n            elif op.startswith('fix'):     a = a\n            elif op.startswith('ice'):     a = a  # for adding icecuber solutions\n            else: raise NotImplementedError(f\"Inversion of operation '{op}' unknown.\")\n        return a\n\n    @staticmethod\n    def invert_mod(a, key, inv_perm=True, is_output=True):\n        if a is None: return a\n        for op in key.split('.')[1:][::-1]:\n            if op.startswith('I'):\n                if is_output: continue\n                op = op[1:]\n            if   op=='rot90':              a = np.rot90(np.rot90(np.rot90(a)))\n            elif op=='transpose':          a = np.swapaxes(a, 0, 1)\n            elif op.startswith('permute'): a = permute_mod(a, op, invert=True) if inv_perm else a\n            elif op.startswith('copy'):    a = np.copy(a)\n            elif op.startswith('out'):     a = a\n            elif op.startswith('ex'):      a = a\n            elif op.startswith('fix'):     a = a\n            elif op.startswith('ice'):     a = a  # for adding icecuber solutions\n            else: raise NotImplementedError(f\"Inversion of operation '{op}' unknown.\")\n        return a\n\n    def __init__(self, queries, replies={}, keys=None, is_orig=False, is_fake=False):\n        if keys is not None: keys = [k for k in keys if k is not None]\n        self.queries = queries if keys is None else {k: queries[k] for k in keys}\n        self.replies = replies if keys is None else {k: replies[k] for k in keys if k in replies}\n        self.is_orig = is_orig\n        self.is_fake = is_fake\n        self.keys = sorted(queries.keys()) if keys is None else keys\n        self.faulty = {}\n        self.transposed_dataset = None\n\n    @classmethod\n    def empty(cls):\n        return cls(queries={}, replies={}, keys=[])\n\n    def change_keys(self, keys, keep_flags=False):\n        flags = dict(is_fake=self.is_fake, is_orig=self.is_orig) if keep_flags else {}\n        return self.__class__(queries=self.queries, replies=self.replies, keys=keys, **flags)\n\n    @classmethod\n    def from_file(cls, queries_file):\n        print(f\"*** Load challanges from '{queries_file}'...\")\n        with open(queries_file) as f: queries = f.read()\n        is_fake = hashlib.md5(queries.encode('utf-8')).hexdigest().lower()=='a6b7dac3cab03abf2eb333e16610d6dc'\n        if is_fake: print(\"*** -> Fake test set detected, setting flag 'is_fake' to True.\")\n        return cls(\n            queries=json.loads(queries),\n            is_fake=is_fake,\n            is_orig=True,\n        )\n\n    def load_replies(self, replies_file):\n        print(f\"*** Load solutions from '{replies_file}'...\")\n        with open(replies_file) as f: replies = f.read()\n        replies_parsed = json.loads(replies)\n        self.replies = {k: replies_parsed[k] for k in self.keys}\n        return self\n\n    def split_multi_replies(self):\n        key_indices = [(k, i) for k in self.keys for i in range(len(self.queries[k]['test']))]\n        return self.__class__(\n            keys=[f'{k}_{i}' for k, i in key_indices],\n            queries={f'{k}_{i}': {'train': self.queries[k]['train'], 'test': [self.queries[k]['test'][i]]} for k, i in key_indices},\n            replies={f'{k}_{i}': [self.replies[k][i]] for k, i in key_indices if k in self.replies},\n        )\n\n    def move_test_to_train(self):\n        new_queries = {k: {'train': self.queries[k]['train'] + [{**t, 'output': self.replies[k][i]} for i, t in enumerate(self.queries[k]['test'])], 'test': []} for k in self.keys}\n        return self.__class__(queries=new_queries, keys=[k for k in self.keys])\n\n    def last_train_ex_for_test(self):\n        assert not self.replies\n        new_queries = {k: {'train': self.queries[k]['train'][:-1], 'test': [{'input': self.queries[k]['train'][-1]['input']}]} for k in self.keys}\n        new_replies = {k: [self.queries[k]['train'][-1]['output']] for k in self.keys}\n        return self.__class__(queries=new_queries, replies=new_replies, keys=[k for k in self.keys])\n\n    def length(self):\n        return len(self.keys)\n\n    def shuffled(self, seed=None):\n        if seed is not None: np.random.seed(seed)\n        return self.__class__(queries=self.queries, replies=self.replies, keys=shuffled(self.keys))\n\n    def sorted(self, **kwargs):\n        return self.__class__(queries=self.queries, replies=self.replies, keys=sorted(self.keys, **kwargs))\n\n    def append(*datasets):\n        return datasets[0].__class__(\n            queries={k: v for d in datasets for k, v in d.queries.items()},\n            replies={k: v for d in datasets for k, v in d.replies.items()},\n            keys   =[k    for d in datasets for k    in d.keys           ],\n        )\n\n    def sort_ex_by_input_size(self, seed=42, reverse=False):\n        np.random.seed(seed)\n        sort_key = lambda ex: np.prod(np.shape(ex['input']))\n        new_queries = {k2: {k: (sorted(np.random.permutation(np.array(v, dtype=object)), key=sort_key, reverse=reverse) if k=='train' else v) for k, v in v2.items()} for k2, v2 in self.queries.items()}\n        return self.__class__(queries=new_queries, replies=self.replies, keys=[k for k in self.keys])\n\n    def interleave(self, block_size, num_gpus=None):\n        keys = np.reshape(self.keys, (-1, block_size)).T\n        if num_gpus is None: return self.change_keys(keys.ravel().tolist())\n        ret, num_gpus = (None, num_gpus) if isinstance(num_gpus, int) else num_gpus\n        keys = np.concatenate([keys, np.full((-keys.shape[0]%num_gpus, keys.shape[1]), None)])\n        keys = np.reshape(keys, (keys.shape[0]//num_gpus, num_gpus, -1)).swapaxes(0, 1).reshape(num_gpus, -1)\n        new_datasets = [self.change_keys(gpu_keys.tolist()) for gpu_keys in keys]\n        return new_datasets if ret is None else new_datasets[ret]\n\n    def remove(self, *datasets):\n        remove_keys = {k for d in datasets for k in d.keys}\n        new_keys = [k for k in self.keys if k not in remove_keys]\n        return self.change_keys(new_keys)\n\n    def keep_key_startswith(self, key_start):\n        new_keys = [k for k in self.keys if k.startswith(key_start)]\n        return self.change_keys(new_keys)\n\n    def mod_single(self, mod_func, descriptor, i, keep_key, inputs_only):\n        queries = {}\n        replies = {}\n        keys    = []\n        for k0 in self.keys:\n            desc = (('copy{i}' if mod_func is np.copy else mod_func.__name__) if descriptor is None else descriptor if isinstance(descriptor, str) else descriptor(self.queries[k0])).format(i=i)\n            func = lambda a, d: np.asarray(mod_func(a) if descriptor is None else mod_func(a, d)).tolist()\n            k1 = k0 if keep_key else f\"{k0}.{'I' if inputs_only else ''}{desc}\"\n            keys.append(k1)\n            queries[k1] = {m: [{t: (func(a, desc) if t=='input' or not inputs_only else a) for t, a in x.items()} for x in e] for m, e in self.queries[k0].items()}\n            if k0 in self.replies:\n                replies[k1] = [func(a, desc) for a in self.replies[k0]]\n        ret = self.__class__(queries=queries, replies=replies, keys=keys)\n        return ret\n\n    def mod(self, mod_func, descriptor=None, n=1, stack=None, keep=False, keep_key=False, shuffle=False, join=True, inputs_only=False):\n        assert not (keep and keep_key)\n        cur = self\n        ret = [cur.shuffled() if shuffle else cur] if keep else []\n        if stack is None: stack = mod_func.__name__.startswith('rot')\n        for i in range(n):\n            cur = (cur if stack else self).mod_single(mod_func, descriptor, i=i, keep_key=keep_key, inputs_only=inputs_only)\n            ret.append(cur.shuffled() if shuffle else cur)\n        return self.__class__.append(*ret) if join else ret\n\n    def get(self, key, formatter):\n        assert formatter.out2_token is None or key in self.replies\n        train = formatter.fmt_train(self.queries[key]['train'])\n        query = formatter.fmt_query(self.queries[key]['test'], i=len(self.queries[key]['train']))\n        reply = formatter.fmt_reply(self.replies[key], self.faulty.get(key)) if key in self.replies else ''\n        text = train+query+reply if reply else formatter.fmt_train(self.queries[key]['train'], last_is_challenge=True)\n        return dict(key=key, train=train, query=query, reply=reply, input=train+query, text=text)\n\n    def as_list(self, formatter):\n        return [self.get(key, formatter) for key in self.keys]\n\n    def as_dataset(self):\n        from datasets import Dataset\n        return Dataset.from_list([{'key': k, 'query': self.queries[k], 'reply': self.replies[k]} for k in self.keys])\n\n    def get_length(self, key, formatter, name, max_of_transposed=False):\n        if formatter is None:\n            if   name=='input': return sum(np.prod(np.shape(v)) for v3 in self.queries[key].values() for v2 in v3 for v in v2.values())\n            elif name=='reply': return sum(np.prod(np.shape(v)) for v in self.replies[key])\n            else: assert False\n        else:\n            datasets = [self]\n            if max_of_transposed:\n                if self.transposed_dataset is None: self.transposed_dataset = self.mod(np.transpose, keep=False, keep_key=True)\n                datasets.append(self.transposed_dataset)\n            return max(len(formatter.tokenizer(ds.get(key, formatter=formatter)[name])['input_ids']) for ds in datasets)\n\n    def get_lengths(self, formatter, name, max_of_transposed=False):\n        return {key: self.get_length(key, formatter=formatter, name=name, max_of_transposed=max_of_transposed) for key in self.keys}\n\n    def sorted_by_len(self, reverse=False, **kwargs):\n        new_keys = [key for _, key in sorted([(v, k) for k, v in self.get_lengths(**kwargs).items()], reverse=reverse)]\n        return self.change_keys(new_keys)\n\n    def filter_by_len(self, min_len=0, max_len=float('inf'), **kwargs):\n        new_keys = [k for k, v in self.get_lengths(**kwargs).items() if min_len<=v<=max_len]\n        return self.change_keys(new_keys)\n\n    def cut_to_query_count(self, max_count, from_end=False):\n        new_queries = {}\n        for k in self.keys:\n            new_queries[k] = q = self.queries[k]\n            while len(q['train'])>max_count: q['train'] = q['train'][:-1] if from_end else q['train'][1:]\n        return self.__class__(queries=new_queries, replies=self.replies, keys=[k for k in self.keys])\n\n    def cut_to_len(self, formatter, name, max_len, max_new_tokens='auto', from_end=False, quiet=False, **kwargs):\n        if max_new_tokens:\n            if max_new_tokens=='auto': max_new_tokens = formatter.max_new_tokens()\n            max_len_old, max_len = max_len, max_len - max_new_tokens\n            if not quiet: print(f'*** Reducing task size to max. {max_len_old} tokens ({max_len} input + {max_new_tokens} generated)...')\n        elif not quiet: print(f'*** Reducing task size to max. {max_len} tokens...')\n        temp_ds = self.change_keys(self.keys)\n        new_keys = []\n        new_queries = {}\n        new_replies = {}\n        for key in (self.keys if quiet else tqdm(self.keys, file=sys.stdout)):\n            reply = temp_ds.replies.get(key)\n            while max_len<temp_ds.get_length(key, formatter=formatter, name=name, **kwargs):\n                query = temp_ds.queries[key]\n                if not key.split('.')[-1].startswith('ex'): key = f\"{key}.ex{''.join(map(str, range(len(query['train']))))}\"\n                key_split = key.split('.')\n                assert key_split[-1].startswith('ex')\n                key = '.'.join(key_split[:-1] + [f'ex{key_split[-1][2:-1] if from_end else key_split[-1][3:]}'])\n                temp_ds.queries[key] = {k: ((v[:-1] if from_end else v[1:]) if k=='train' else v) for k, v in query.items()}\n                if reply is not None: temp_ds.replies[key] = reply\n            new_keys.append(key)\n            new_queries[key] = temp_ds.queries[key]\n            if reply is not None: new_replies[key] = reply\n        return self.__class__(keys=new_keys, queries=new_queries, replies=new_replies)\n\n    def shuffle_ex(self, perm=None, keep_max=None):\n        new_keys = []\n        new_queries = {}\n        new_replies = {}\n        for key in self.keys:\n            n = len(self.queries[key]['train'])\n            p = np.random.permutation(n) if perm is None else perm\n            if keep_max is not None: p = p[:keep_max]\n            new_key = f'{key}.ex' + ('-' if (p.max()>9) else '').join(map(str, p.tolist()))\n            new_keys.append(new_key)\n            new_queries[new_key] = {k: (np.array(v, dtype=object)[p].tolist() if k=='train' else v) for k, v in self.queries[key].items()}\n            if key in self.replies: new_replies[new_key] = self.replies[key]\n        return self.__class__(queries=new_queries, replies=new_replies, keys=new_keys)\n\n    def shuffle_rp(self, keep_max=None):\n        new_keys = []\n        new_queries = {}\n        new_replies = {}\n        for key in self.keys:\n            n = len(self.queries[key]['test'])\n            p = np.random.permutation(n)\n            if keep_max is not None: p = p[:keep_max]\n            new_key = f'{key}.rp' + ('-' if (p.max()>9) else '').join(map(str, p.tolist()))\n            new_keys.append(new_key)\n            new_queries[new_key] = {k: (np.array(v, dtype=object)[p].tolist() if k=='test' else v) for k, v in self.queries[key].items()}\n            if key in self.replies: new_replies[new_key] = np.array(self.replies[key], dtype=object)[p].tolist()\n        return self.__class__(queries=new_queries, replies=new_replies, keys=new_keys)\n\n    def append_to_keys(self, test):\n        return self.change_keys([f'{k}{text}' for k in self.keys])\n\n    def random_select(self, n):\n        keys = np.array(self.keys).reshape(n, -1).T\n        choice = np.random.randint(0, n, size=[len(keys)])\n        return self.change_keys(keys[np.arange(len(keys)), choice])\n\n    def augment(self, tp=False, rot=False, n=1, perm=None, perm_append=False, shfl_keys=False, shfl_ex=False, seed=None, quiet=False, inputs_only=False):\n        if not quiet: print(f\"*** Augment dataset{' (inputs only)' if inputs_only else ''}...\")\n        np.random.seed(seed)\n        d = self\n        if tp: d = d.mod(np.transpose, keep=True, inputs_only=inputs_only)\n        if tp=='rand': d = d.random_select(n=2)\n        if rot: d = d.mod(np.rot90, n=3, keep=True, inputs_only=inputs_only)\n        if rot=='rand': d = d.random_select(n=4)\n        if perm is None and n<=1: d = d.shuffled() if shfl_keys else d\n        else: d = d.mod(*([np.copy] if perm is None else globals()[f\"permute_{perm}\"]), n=n, shuffle=shfl_keys, keep=perm_append, inputs_only=inputs_only)\n        np.random.seed(seed)\n        if shfl_ex: d = d.shuffle_ex()\n        return d\n\n    def remove_replies(self):\n        return self.__class__(queries=self.queries, replies={}, keys=[k for k in self.keys])\n\n    def split_at_pos(self, pos, random_seed=None):\n        keys = self.keys\n        if random_seed is not None:\n            np.random.seed(random_seed)\n            keys = np.random.permutation(keys)\n        if isinstance(pos, float): pos = int(pos * len(self.keys) + 0.5)\n        keys_split = [keys[:pos], keys[pos:]]\n        return tuple(self.change_keys(new_keys, keep_flags=True) for new_keys in keys_split)\n\n    def get_submission(self, results=None):\n        assert self.is_orig==True, 'Must be run on original dataset.'\n        submission = {k: [{f'attempt_{i+1}': [[0]] for i in range(2)} for _ in range(len(self.queries[k]['test']))] for k in self.keys}\n        if results is not None: self.fill_submission(results, submission)\n        return submission\n\n    @staticmethod\n    def fill_submission(results, submission):\n        print(f'*** Generating submission for {len(results)} outputs...')\n        for k, v in results.items():\n            base_id, base_nr = k.split('_')\n            target_dict = submission[base_id][int(base_nr)]\n            for i, g in enumerate(v[:len(target_dict)]):\n                target_dict[f'attempt_{i+1}'] = g.tolist()\n\n    def validate_submission(self, submission):\n        assert self.is_orig==True, 'Must be run on original dataset.'\n        score = 0\n        for k, v in self.replies.items():\n            for i, r in enumerate(v):\n                for attempt in ['attempt_1', 'attempt_2']:\n                    if np.array_equal(r, submission[k][i][attempt]):\n                        score += 1 / len(v)\n                        break\n        return score\ndef get_class_MyDataCollator(cache=[]):\n    if not cache:\n        from trl import DataCollatorForCompletionOnlyLM\n        class MyDataCollator(DataCollatorForCompletionOnlyLM):\n            def setup(self, out2_token_id=None, fault_token_id=None, fault_freq=0, sample_tries=8, mask_first_output=False):\n                self.out2_token_id = out2_token_id\n                self.fault_token_id = fault_token_id\n                self.fault_freq = fault_freq\n                self.sample_tries = sample_tries\n                self.mask_first_output = mask_first_output\n                return self\n\n            def torch_call(self, examples):\n                batch = super().torch_call(examples)\n                if self.out2_token_id is not None:\n                    assert not self.fault_freq\n                    for i in range(len(batch['input_ids'])):\n                        end_pos = ((batch['labels'][i] != -100              ).nonzero().max()).item() + 1\n                        mid_pos = ((batch['labels'][i] == self.out2_token_id).nonzero().max()).item() + 1\n                        beg_pos = mid_pos - (end_pos - mid_pos)\n                        batch['labels'][i][beg_pos:mid_pos] = batch['labels'][i][mid_pos:end_pos]\n                elif self.fault_freq:\n                    for i in range(len(batch['input_ids'])):\n                        end_pos = ((batch['labels'][i] != -100).nonzero().max()).item() + 1\n                        if not isinstance(self.fault_freq, float):\n                            eos_token_id = batch['labels'][i][end_pos - 1]\n                            num_examples = (batch['labels'][i] == eos_token_id).sum().item() - 1\n                            fault_freq = self.fault_freq[num_examples]\n                        else: fault_freq = self.fault_freq\n                        if random.random() < fault_freq:\n                            beg_pos = ((batch['labels'][i][:end_pos]==-100).nonzero().max()).item() + 1\n                            fault_pos = random.randint(beg_pos, end_pos-2)\n                            fault_tok = batch['labels'][i][fault_pos].item()\n                            for t in range(self.sample_tries):\n                                new_tok = batch['labels'][i][random.randint(beg_pos, end_pos-2)].item()\n                                if fault_tok!=new_tok:\n                                    batch['input_ids'][i][fault_pos] = new_tok\n                                    batch['labels'][i][fault_pos+1:end_pos] = self.fault_token_id\n                                    break\n                for i in range(len(batch['labels'])):\n                    for _ in range(self.mask_first_output):\n                        beg_pos = ((batch['labels'][i] != -100).nonzero().min()).item()\n                        mid_pos = ((batch['labels'][i][beg_pos:] == -100).nonzero().min()).item() + beg_pos\n                        end_pos = ((batch['labels'][i] != -100).nonzero().max()).item() + 1\n                        if mid_pos<end_pos: batch['labels'][i][beg_pos:mid_pos] = -100\n                return batch\n        cache.append(MyDataCollator)\n    return cache[0]\n\nclass ArcFormatter(object):\n    def __init__(self, inp_prefix, out_prefix, arr_sep, out2_use=False, out2_token=None, arr_beg='', arr_end='', pretext='', pre_out=None, exa_sep='', exa_end='', qry_prefix=None, rpl_prefix=None, rpl_sep=None, dec_sep=None, min_wid=0, min_pad='', pretext_corpus_split='', masking=0, tokenizer=None, collator_kwargs={}, repeat_input_aug=None, repeat_input_pre=None):\n        self.tokenizer = tokenizer\n        self.inp_prefix = inp_prefix\n        self.out_prefix = out_prefix\n        self.out2_token = out2_token\n        self.out2_use = out2_use\n        assert not out2_use or out2_token is not None\n        assert not out2_use or masking in [1, 2]\n        assert masking!=2 or out2_use or rpl_prefix is not None\n        self.qry_prefix = qry_prefix if qry_prefix is not None else inp_prefix\n        self.rpl_prefix = rpl_prefix if rpl_prefix is not None else out_prefix\n        self.rpl_sep = rpl_sep if rpl_sep is not None else self.rpl_prefix\n        self.arr_sep = arr_sep\n        self.arr_beg = arr_beg\n        self.arr_end = arr_end\n        self.pretext = pretext\n        self.pre_out = pre_out\n        self.pre_out_empty = ['']*99\n        self.pretext_corpus_split = pretext_corpus_split\n        self.exa_sep = exa_sep\n        self.exa_end = exa_end\n        self.dec_sep = arr_sep if dec_sep is None else dec_sep\n        self.min_wid = min_wid\n        self.min_pad = min_pad\n        self.masking = masking\n        self.collator_kwargs = collator_kwargs\n        self.repeat_input_aug = repeat_input_aug\n        self.repeat_input_pre = repeat_input_pre\n\n    def fmt_array(self, array):\n        return self.arr_beg + self.arr_sep.join(str(row).replace(' ', '').replace(',', '').replace('[', '').replace(']', '')+self.min_pad*max(0, self.min_wid-len(row)) for row in array) + self.arr_end\n\n    def get_pre_out(self, pretext_split):\n        if self.pre_out is None: return self.pre_out_empty\n        if pretext_split: return [self.pretext_corpus_split.join(list(p) + ['']) for p in self.pre_out]\n        return self.pre_out\n\n    def fmt_train(self, train, last_is_challenge=False, pretext_split=False):\n        po = self.get_pre_out(pretext_split=pretext_split)\n        ex = [(f\"{self.fmt_query([x], i, pretext_split=pretext_split)}{self.fmt_reply([x['output']])}\" if last_is_challenge and i+1==len(train) else\n               f\"{self.inp_prefix}{self.fmt_array(x['input'])}{self.repeat_input(x, no_aug=pretext_split)}{po[i]}{self.out_prefix}{self.fmt_array(x['output'])}\") for i, x in enumerate(train)]\n        pre = self.pretext_corpus_split.join(list(self.pretext)+['']) if pretext_split else self.pretext\n        end = '' if last_is_challenge else (self.exa_end + self.tokenizer.eos_token)\n        return pre + (self.exa_end + self.tokenizer.eos_token + self.exa_sep).join(ex) + end\n\n    def fmt_query(self, query, i, pretext_split=False):\n        po = self.get_pre_out(pretext_split=pretext_split)\n        return ''.join(f\"{self.qry_prefix}{self.fmt_array(x['input'])}{self.repeat_input(x, no_aug=pretext_split)}{po[i]}{self.rpl_prefix}\" for x in query[:1])\n\n    def repeat_input(self, x, no_aug=False):\n        if self.repeat_input_aug is None: return ''\n        return f\"{self.repeat_input_pre}{self.fmt_array(((lambda x: x) if no_aug else self.repeat_input_aug)(x['input']))}\"\n\n    def fmt_reply(self, reply, fault=None):\n        ids = self.fmt_array(reply[0]) + self.exa_end + self.tokenizer.eos_token\n        if self.out2_use:\n            if fault is None: fault = reply\n            ids = self.fmt_array(fault[0]) + self.exa_end + self.out2_token + ids\n        return ids\n\n    def quick_test(self, decoded, done):\n        sp = decoded.split(self.tokenizer.eos_token)[0].split(self.dec_sep)\n        sl = len(sp[0])\n        is_prefix = sl>0 and len(sp[-1])<=sl and (len(sp)==1 or len(sp[-2])==sl) and all(x.isdigit() for x in sp[-1])\n        return is_prefix and (not done or len(sp[-1])==0 or len(sp[-1])==sl)\n\n    @staticmethod\n    def is_valid_solution(guess):\n        return isinstance(guess, np.ndarray) and guess.ndim == 2 and all(0 < x <= 30 for x in guess.shape)\n\n    def max_new_tokens(self, safety_margin=1):\n        max_sized_reply = np.zeros([30, 30], dtype=int)\n        tokenized = self.tokenizer(self.fmt_reply([max_sized_reply]))['input_ids']\n        max_new_tokens = len(tokenized)\n        if tokenized[0]==self.tokenizer.bos_token_id: max_new_tokens -= 1\n        return max_new_tokens + safety_margin\n\n    def de_tokenize(self, tokens, scores=None):\n        import torch\n        tokens_cut = cut_at_token(tokens, self.tokenizer.eos_token_id)\n        de_tokenized = self.tokenizer.batch_decode([tokens_cut])[0]\n        score_val = None\n        if scores is not None:\n            tokens_with_eos = tokens[:len(tokens_cut)+1]\n            score_val = torch.nn.functional.log_softmax(torch.tensor(scores), dim=-1).numpy().copy()[np.arange(len(tokens_with_eos)), tokens_with_eos].sum()\n            number_token_ids = [self.tokenizer.vocab[k] for k in map(str, range(10))]\n            fault_token_id = self.collator_kwargs.get('fault_token_id')\n            if fault_token_id is not None: number_token_ids.append(fault_token_id)\n            number_token_ids = np.array(number_token_ids)\n            number_positions = (tokens_cut[..., np.newaxis] == number_token_ids).any(-1)\n            scores = scores[:len(tokens_cut), number_token_ids][number_positions]\n            scores = torch.nn.functional.log_softmax(torch.tensor(scores), dim=-1)[:, :10].numpy().copy()\n        return max(len(tokens)+1, len(tokens_cut)), score_val, de_tokenized, scores\n\n    def decode_to_array_single(self, text, score=None, limit_rows=30):\n        try:\n            by_rows = [row for row in [[int(x) for x in line if x.isdigit()] for line in text.split(self.dec_sep)] if len(row)]\n            if limit_rows and len(by_rows) > limit_rows:\n                by_rows = by_rows[:limit_rows]\n                limited = True\n            else: limited = False\n            decoded = np.array(by_rows, dtype=int)\n            if self.is_valid_solution(decoded):\n                try:\n                    assert score is not None\n                    decoded_flat = decoded.ravel()\n                    if limited: score = score[:len(decoded_flat)]\n                    score_all = score.reshape(decoded.shape + score.shape[1:])\n                    score_result = score[range(len(decoded_flat)), decoded_flat]\n                    score_reshaped = score_result.reshape(decoded.shape)\n                    score_cum_reshaped = score_result.cumsum().reshape(score_reshaped.shape)\n                    score_all_cum = score_cum_reshaped[..., np.newaxis] - score_reshaped[..., np.newaxis] + score_all\n                except: score_reshaped = score_cum_reshaped = np.full(decoded.shape, -float('inf'))\n                return {'output': decoded, 'score': score_reshaped, 'score_cum': score_cum_reshaped, 'score_all': score_all, 'score_all_cum': score_all_cum}\n        except: pass\n        return {}\n\n    def decode_to_array(self, text, score=None, limit_rows=30):\n        if not self.out2_use: text, score = [text], [score]\n        else:\n            text = text.split(self.out2_token)\n            if score is None: score = [None]*len(text)\n            else:\n                lengths = np.cumsum([len(list(filter(str.isdigit, t))) for t in text])\n                score = [score[s:e] for s, e in zip([0]+lengths[:-1].tolist(), lengths)]\n        return [self.decode_to_array_single(t, s) for t, s in zip(text, score)]\n\n    def get_corpus(self):\n        try:\n            old_min_wid, self.min_wid = self.min_wid, min(self.min_wid, 2)\n            return self.fmt_train([{'input': [[i] for i in range(10)], 'output': [[i] for i in range(10)]}]*3, last_is_challenge=True, pretext_split=True)\n        finally: self.min_wid = old_min_wid\n\n    def get_data_collator(self):\n        if not self.masking: return None\n        from transformers import DataCollatorForLanguageModeling\n        collator_params = dict(tokenizer=self.tokenizer, mlm=False)\n        pass_out2_token = self.tokenizer.vocab[self.out2_token] if self.out2_use and self.masking==1 else None\n        if self.masking:\n            assert not self.collator_kwargs.get('mask_first_output') or self.masking==1\n            data_collator = get_class_MyDataCollator()(\n                **collator_params,\n                instruction_template=[self.inp_prefix, self.tokenizer.bos_token][self.masking - 1],\n                response_template=[self.out_prefix, (self.out2_token if self.out2_use else self.rpl_sep)][self.masking - 1],\n            ).setup(out2_token_id=pass_out2_token, **self.collator_kwargs)\n        else:\n            assert not self.collator_kwargs, 'only supported with masking on'\n            data_collator = DataCollatorForLanguageModeling(**collator_params)\n        return data_collator\n\n    def get_output_token_ids(self):\n        assert not self.out2_use\n        num_tokens = [self.tokenizer.vocab[str(i)] for i in range(10)]\n        sep_tokens = [tok for txt in [self.arr_beg, self.arr_sep, self.arr_end, self.exa_sep] if txt for tok in self.tokenizer(txt)['input_ids'][1:]]\n        sep_tokens.append(self.tokenizer.eos_token_id)\n        return num_tokens + sorted(set(sep_tokens))\n\nArcFormatter_pretext2 = lambda **kwargs: ArcFormatter(masking=1, inp_prefix='I', out_prefix='O', arr_sep='\\n', arr_end='\\n', pretext='ABCDEFGHJKLMNPQRSTUVWXYZ', pretext_corpus_split='\\n', **kwargs)\nArcFormatter_pretext3 = lambda **kwargs: ArcFormatter(masking=1, inp_prefix='I', out_prefix='O', arr_sep='\\n', arr_end='\\n', pretext='ABCDEFGHJKLMNPQRSTUVWXYZabcdefghjklmnpqrstuvwxyz', pretext_corpus_split='\\n', **kwargs)\nArcFormatter_premix_2 = lambda **kwargs: ArcFormatter(masking=1, inp_prefix='I', out_prefix='O', arr_sep='\\n', arr_end='\\n', pretext='ABCDEFGHJKLMNPQRSTUVWXYZ', pre_out=['+/-=']*99, pretext_corpus_split='\\n', **kwargs)\nArcFormatter_premix_3 = lambda **kwargs: ArcFormatter(masking=1, inp_prefix='I', out_prefix='O', arr_sep='\\n', arr_end='\\n', pretext='ABCDEFGHJKLMNPQRSTUVWXYZabcdefghjklmnpqrstuvwxyz', pre_out=['+/-=']*99, pretext_corpus_split='\\n', **kwargs)\n\navailable_formatters = dict(\n    ArcFormatter_pretext2=ArcFormatter_pretext2,\n    ArcFormatter_pretext3=ArcFormatter_pretext3,\n    ArcFormatter_premix_2=ArcFormatter_premix_2,\n    ArcFormatter_premix_3=ArcFormatter_premix_3,\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:56:07.748636Z","iopub.execute_input":"2025-06-27T19:56:07.749013Z","iopub.status.idle":"2025-06-27T19:56:07.771903Z","shell.execute_reply.started":"2025-06-27T19:56:07.748979Z","shell.execute_reply":"2025-06-27T19:56:07.770841Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting arc_loader.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%%writefile selection.py\nimport numpy as np\n\ndef hashable(guess):\n    return tuple(map(tuple, guess))\n\ndef make_unique(guess_list, indices=None):\n    used = set()\n    out = []\n    out_ind = []\n    for i, g in enumerate(guess_list):\n        h = hashable(g)\n        if h not in used:\n            used.add(h)\n            out.append(np.array(g))\n            if indices is not None: out_ind.append(indices[i])\n    return out if indices is None else (out, out_ind)\n\ndef first_only(guesses):\n    return [g['output'] for g in guesses.values()][:1]\n\ndef keep_order(guesses):\n    return [g['output'] for g in guesses.values()]\n\ndef keep_order_unique(guesses):\n    return make_unique(keep_order(guesses))\n\ndef get_best_shape_by_score(guess_list, getter, once_per_result=True):\n    seen_outputs = set()\n    shape_scores = {}\n    for i, g in enumerate(guess_list):\n        shape = tuple(g['output'].shape)\n        scores = shape_scores[shape] = shape_scores.get(shape, [[], []])\n        scores[1].append(i)\n        h = hashable(g['output'])\n        if h in seen_outputs: continue\n        if once_per_result: seen_outputs.add(h)\n        scores[0].append(g)\n    shape_scores = [(getter(scores), shape, indices) for shape, (scores, indices) in shape_scores.items()]\n    shape_scores = sorted(shape_scores, key=(lambda x: x[0]), reverse=True)\n    return shape_scores[0]\n\ndef score_sum(guesses, getter, shape_getter=None, prefer_common_shape=True):\n    if shape_getter is None: shape_getter = getter\n    guess_list = list(guesses.values())\n    common_shape_indices = set(get_best_shape_by_score(guess_list, shape_getter)[2]) if prefer_common_shape else []\n    scores = {}\n    for i, g in enumerate(guess_list):\n        h = hashable(g['output'])\n        x = scores[h] = scores.get(h, [i in common_shape_indices, [], g['output']])\n        x[1].append(g)\n    scores = [(cs, getter(sc), o) for cs, sc, o in scores.values()]\n    scores = sorted(scores, key=(lambda x: x[:2]), reverse=True)\n    ordered_outputs = [x[-1] for x in scores]\n    return ordered_outputs\n\ngetter_all_probsum = lambda guesses: sum(np.exp(g['score_val']) for g in guesses)\ndef score_all_probsum(guesses): return score_sum(guesses, getter_all_probsum)\n\ndef getter_full_probmul(p):\n    def _getter(guesses, baseline=p):\n        inf_score = sum([g['score_val']+baseline for g in guesses])\n        aug_score = np.mean([sum(s+baseline for s in g['score_multi_nl']) for g in guesses])\n        return inf_score + aug_score\n    return _getter\n\ndef score_full_probmul_3(guesses): return score_sum(guesses, getter_full_probmul(3), prefer_common_shape=False)\n\nselection_algorithms = [\n    first_only,\n    keep_order,\n    keep_order_unique,\n    score_all_probsum,\n    score_full_probmul_3,\n]","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:56:18.271740Z","iopub.execute_input":"2025-06-27T19:56:18.272114Z","iopub.status.idle":"2025-06-27T19:56:18.280157Z","shell.execute_reply.started":"2025-06-27T19:56:18.272084Z","shell.execute_reply":"2025-06-27T19:56:18.278864Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting selection.py\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile async_tools.py\nimport sys\nimport asyncio\n\nasync def stream_reader(stream, id, to):\n    id = '' if id is None else f'{id}. '\n    data = b''\n    while True:\n        read = await stream.read(n=4096)\n        if not read: break\n        if to is not None:\n            *complete_lines, data = (data + read + b'X').splitlines()\n            data = data[:-1]\n            for line in complete_lines:\n                line = line.rstrip()\n                if line: print(f\"{id}{line.decode('utf-8')}\", file=to, end='\\n', flush=True)\n\nasync def wait_for_subprocess(subprocess, print_output=False, id=None):\n    await asyncio.gather(\n            stream_reader(subprocess.stdout, id, (sys.stdout if print_output else None)),\n            stream_reader(subprocess.stderr, id, (sys.stderr if print_output else None)),\n        )\n    return await subprocess.wait()\n\nasync def wait_for_subprocesses(*processes, print_output=False):\n    return await asyncio.gather(*[wait_for_subprocess(p, print_output=print_output, id=i if len(processes)>1 else None) for i, p in enumerate(processes)])","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:56:22.209902Z","iopub.execute_input":"2025-06-27T19:56:22.210268Z","iopub.status.idle":"2025-06-27T19:56:22.217212Z","shell.execute_reply.started":"2025-06-27T19:56:22.210236Z","shell.execute_reply":"2025-06-27T19:56:22.215992Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting async_tools.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%%writefile common_stuff.py\n# common configuration for training and evaluation\nfrom arc_loader import *\nfrom model_runner import *\nfrom selection import *\nfrom async_tools import *\nimport time\n\n# paths\ntmp_dir = '/kaggle/temp'\narc_challenge_file = '/kaggle/input/arc-agi/arc-agi_test_challenges.json'\narc_solutions_file = '/kaggle/input/arc-agi/arc-agi_training_solutions.json'\nmodel_temp_storage = os.path.join(tmp_dir, 'finetuned_model')\ninfer_temp_storage = os.path.join(tmp_dir, 'inference_outputs')\nscore_temp_storage = os.path.join(tmp_dir, 'inference_scoring')\n\n# load datasets\narc_test_set = ArcDataset.from_file(arc_challenge_file)\nif arc_test_set.is_fake: arc_test_set.load_replies(arc_solutions_file)\n#arc_test_set.is_fake = False  # force full run\n#arc_train_set = ArcDataset.from_file('/kaggle/input/arc-agi/arc-agi_training_challenges.json')\n\n# models\nbase_model, MyFormatter, perm_aug, max_seq_length_train, mask_first = '/kaggle/input/wb55l_nemomini_fulleval/transformers/default/1', ArcFormatter_premix_3, 'rnd_all', 4224, 0\n\n# training & inference\ntrain_epochs = 4\nmulti_gpu_train = True\nmulti_gpu_random_split = True\nmax_seq_length_infer = 8192\nprime_on_single_task = False\ninfer_params = dict(min_prob=0.17, store=infer_temp_storage, use_turbo=True)\n\n# scoring\nuse_aug_score = True\naug_score_params = dict(tp=True, rot=True, perm=perm_aug, shfl_ex=True, make_unique=True, max_len=max_seq_length_infer)\nsubmission_select_algo = score_full_probmul_3 if use_aug_score else score_all_probsum\n\ndef prepare_run(model_path, load_lora=None, train=False, gpu=None, **kwargs):\n    if gpu is not None:\n        os.environ[\"CUDA_DEVICE_ORDER\"   ] = \"PCI_BUS_ID\"\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n\n    model, tokenizer, formatter = prepare_model(  # base model configuration\n        model=model_path,\n        local_files_only=True,\n        mode='unsloth_4bit',\n        #shrink_embedding=8000,\n        max_seq_length=max_seq_length_train,\n        formatter=MyFormatter,\n        peft=([dict(\n            r=64,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n            target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'embed_tokens', 'lm_head'],\n            lora_alpha=16,\n            lora_dropout=0,  # Supports any, but = 0 is optimized\n            bias=\"none\",  # Supports any, but = \"none\" is optimized\n            use_gradient_checkpointing=True,  # True or \"unsloth\" for very long context\n            random_state=42,\n            use_rslora=True,  # We support rank stabilized LoRA\n            loftq_config=None,  # And LoftQ\n        )] if train or load_lora else []) + ([load_lora] if load_lora else []),\n        **kwargs\n    )\n    \n    if train and mask_first: formatter.collator_kwargs.update(mask_first_output=mask_first)\n\n    return model, formatter\n\ndef prepare_dataset(formatter, train, gpu=None):\n    ds = arc_test_set\n    if multi_gpu_train and gpu is not None:\n        if multi_gpu_random_split:\n            ds = ds.shuffled(seed=123)\n            ds = ds.split_at_pos(len(ds.keys)//2)[gpu]\n        else:\n            ds = ds.sorted_by_len(formatter=formatter, name='input', max_of_transposed=True)\n            assignment = ([0,1,1,0]*ds.length())[:ds.length()][::-1]\n            ds = ds.change_keys((np.array(ds.keys)[np.array(assignment)==gpu]).tolist())\n    if train:\n        ds = ds.remove_replies()\n        ds = ds.augment(tp=True, rot=True, perm=perm_aug, n=(2 if arc_test_set.is_fake else train_epochs), shfl_ex=True, shfl_keys=True)\n        ds = ds.cut_to_len(formatter=formatter, name='text', max_len=max_seq_length_train, max_new_tokens=0)\n        if arc_test_set.is_fake: ds = ds.sorted_by_len(formatter=formatter, name='text', reverse=True)\n    else:\n        ds = ds.sorted_by_len(formatter=formatter, name='input', max_of_transposed=True)\n        ds = ds.split_multi_replies()\n        ds = ds.augment(tp=True, rot=True, n=2, seed=42, perm=perm_aug, shfl_ex=True).interleave(ds.length())\n        ds = ds.cut_to_len(formatter=formatter, name='input', max_len=max_seq_length_infer)\n        if arc_test_set.is_fake: ds.keys = ds.keys[:128] #ds.keys[::-1][::5][::-1]\n    return ds\n\ndef start_training(gpu):\n    try:\n        storage_path = f'{model_temp_storage}_gpu{gpu}'\n        if (gpu==0 or multi_gpu_train) and not os.path.exists(storage_path):\n            with RemapCudaOOM():\n                model, formatter = prepare_run(base_model, train=True, gpu=gpu)\n                dataset = prepare_dataset(formatter, train=True, gpu=gpu if multi_gpu_train else None)\n                model, trainer_stats = training_run(\n                    model, formatter, dataset, store=storage_path,\n                    max_seq_length=max_seq_length_train,\n                    grad_acc_fix=False,\n                    train_args=dict(\n                        per_device_train_batch_size=2,\n                        gradient_accumulation_steps=2,\n                        warmup_steps=100,\n                        num_train_epochs=1,\n                        max_steps=20 if arc_test_set.is_fake else -1,\n                        learning_rate=1e-4,\n                        embedding_learning_rate=1e-5,\n                        logging_steps=10,\n                        optim=\"adamw_8bit\",\n                        weight_decay=0.01,  # 0.01,\n                        lr_scheduler_type='cosine',  # \"linear\", \"cosine\",\n                        seed=42,\n                        output_dir=os.path.join(tmp_dir, 'checkpoints'),\n                        save_strategy=\"no\",\n                        report_to='none',\n                    ),\n                )\n                mem_info()\n    finally: os.makedirs(f'{storage_path}_done', exist_ok=True)\n\ndef start_inference(gpu):\n    storage_path = f'{model_temp_storage}_gpu{gpu if multi_gpu_train else 0}'\n    while not os.path.exists(f'{storage_path}_done'): time.sleep(15)\n    with RemapCudaOOM():\n        model, formatter = prepare_run(storage_path, gpu=gpu)\n        dataset = prepare_dataset(formatter, train=False, gpu=gpu)\n        retrainer = None if not prime_on_single_task else Retrainer(\n            n=32,\n            aug_opts=dict(perm=perm_aug, shfl_ex=True),\n            reload_state_dict=get_and_fix_peft_weights(storage_path),\n            formatter=formatter,\n            max_seq_length=max_seq_length_infer,\n            grad_acc_fix=False,\n            train_args=dict(\n                per_device_train_batch_size=2,\n                gradient_accumulation_steps=2,\n                warmup_steps=4,\n                num_train_epochs=1,\n                learning_rate=1e-4,\n                embedding_learning_rate=0,\n                logging_steps=8,\n                optim=\"adamw_8bit\",\n                weight_decay=0.00,  # 0.01,\n                lr_scheduler_type='constant',  # \"linear\", \"cosine\",\n                seed=42,\n                output_dir='tmp_output',\n                save_strategy='no',\n                report_to='none',\n            ),\n        )\n        decoder = Decoder(formatter, arc_test_set.split_multi_replies(), n_guesses=2, prob_baseline=0.05)\n        inference_run_v2(model, formatter, dataset, decoder, retrain=retrainer, **infer_params)\n        if use_aug_score or arc_test_set.is_fake: decoder.calc_augmented_scores(model=model, store=score_temp_storage, **aug_score_params)\n        mem_info()\n\nclass RemapCudaOOM:\n    def __enter__(self): pass\n    def __exit__(self, exc_type, exc_value, traceback):\n        oom_errors = [\"CUDA out of memory\", \"Make sure you have enough GPU RAM\", \"does not fit any GPU's remaining memory\"]\n        if exc_value and any(x in str(exc_value) for x in oom_errors):\n            with open('submission.json', 'w') as f: f.write('cause submission scoring error')\n","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:56:26.988323Z","iopub.execute_input":"2025-06-27T19:56:26.988705Z","iopub.status.idle":"2025-06-27T19:56:26.998786Z","shell.execute_reply.started":"2025-06-27T19:56:26.988672Z","shell.execute_reply":"2025-06-27T19:56:26.997679Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Overwriting common_stuff.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from common_stuff import *\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nif not os.path.exists(os.path.join(tmp_dir, 'unsloth_installed')):  # unsloth offline install - https://stackoverflow.com/a/51646354\n    !pip uninstall --yes torch accelerate\n    !pip install --no-index --find-links=/kaggle/input/unsloth-2024-9-post4/wheelhouse unsloth\n    #!pip uninstall --yes accelerate fastai torch torchaudio transformers\n    #!pip install --no-index --find-links=/kaggle/input/unsloth-2024-10-7/wheelhouse unsloth  # do not use grad_acc_fix - trains very slow\n    #!sed -i 's/if ((post_check - pre_check) >= 1).sum() > 1:/if False:/g' /opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py\n    # fix delay bug in get_statistics()\n    !sed -i 's/^def get_statistics():/def get_statistics():\\n if False:/g' /opt/conda/lib/python3.10/site-packages/unsloth/models/_utils.py\n    # fix faulty unsloth multi-gpu detection\n    !sed -i \"s/raise RuntimeError('Unsloth currently does not support multi GPU setups - but we are working on it!')/pass/g\" /opt/conda/lib/python3.10/site-packages/unsloth/tokenizer_utils.py /opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py /opt/conda/lib/python3.10/site-packages/unsloth/models/vision.py\n    os.makedirs(os.path.join(tmp_dir, 'unsloth_installed'), exist_ok=True)\n    print('Unsloth installed & patched.')\n\nfor gpu in [0, 1]: \n    signal_path = f'{model_temp_storage}_gpu{gpu}_done'\n    if os.path.exists(signal_path): os.rmdir(signal_path)\n\nif arc_test_set.is_fake:  # cleanup? (for debugging)\n    #!rm -R /kaggle/temp/finetuned_model*\n    #!rm -R /kaggle/temp/inference_outputs\n    #!rm -R /kaggle/temp/inference_scoring\n    #!ls /kaggle/temp\n    pass","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:56:35.949464Z","iopub.execute_input":"2025-06-27T19:56:35.949828Z","iopub.status.idle":"2025-06-27T19:58:56.654508Z","shell.execute_reply.started":"2025-06-27T19:56:35.949783Z","shell.execute_reply":"2025-06-27T19:58:56.653203Z"},"trusted":true},"outputs":[{"name":"stdout","text":"*** Load challanges from '/kaggle/input/arc-agi/arc-agi_test_challenges.json'...\n*** -> Fake test set detected, setting flag 'is_fake' to True.\n*** Load solutions from '/kaggle/input/arc-agi/arc-agi_training_solutions.json'...\nFound existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nFound existing installation: accelerate 0.33.0\nUninstalling accelerate-0.33.0:\n  Successfully uninstalled accelerate-0.33.0\nLooking in links: /kaggle/input/unsloth-2024-9-post4/wheelhouse\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/unsloth-2024.9.post4-py3-none-any.whl\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (from unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (from unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (from unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from unsloth)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth) (21.3)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/tyro-0.8.11-py3-none-any.whl (from unsloth)\nRequirement already satisfied: transformers<4.45.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.44.0)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (2.21.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth) (5.9.3)\nRequirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth) (1.26.4)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/accelerate-0.34.2-py3-none-any.whl (from unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/trl-0.11.1-py3-none-any.whl (from unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/peft-0.13.0-py3-none-any.whl (from unsloth)\nRequirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from unsloth) (0.24.6)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from unsloth)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.1->unsloth) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->unsloth) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch>=2.4.0->unsloth)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.45.0->unsloth) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<4.45.0->unsloth) (0.19.1)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth) (13.7.1)\nProcessing /kaggle/input/unsloth-2024-9-post4/wheelhouse/shtab-1.7.1-py3-none-any.whl (from tyro->unsloth)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\nInstalling collected packages: triton, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, xformers, bitsandbytes, accelerate, trl, peft, unsloth\nSuccessfully installed accelerate-0.34.2 bitsandbytes-0.44.0 hf-transfer-0.1.8 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 peft-0.13.0 shtab-1.7.1 torch-2.4.1 triton-3.0.0 trl-0.11.1 tyro-0.8.11 unsloth-2024.9.post4 xformers-0.0.28.post1\nUnsloth installed & patched.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%python --bg --proc train_proc0\nfrom common_stuff import *\nstart_training(gpu=0)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:59:25.102019Z","iopub.execute_input":"2025-06-27T19:59:25.102492Z","iopub.status.idle":"2025-06-27T19:59:25.119519Z","shell.execute_reply.started":"2025-06-27T19:59:25.102443Z","shell.execute_reply":"2025-06-27T19:59:25.118270Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%%python --bg --proc train_proc1\nfrom common_stuff import *\nstart_training(gpu=1)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:59:27.685426Z","iopub.execute_input":"2025-06-27T19:59:27.686510Z","iopub.status.idle":"2025-06-27T19:59:27.695600Z","shell.execute_reply.started":"2025-06-27T19:59:27.686449Z","shell.execute_reply":"2025-06-27T19:59:27.694320Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"%%python --bg --proc infer_proc0\nfrom common_stuff import *\nstart_inference(gpu=0)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:59:30.569952Z","iopub.execute_input":"2025-06-27T19:59:30.570446Z","iopub.status.idle":"2025-06-27T19:59:30.582648Z","shell.execute_reply.started":"2025-06-27T19:59:30.570393Z","shell.execute_reply":"2025-06-27T19:59:30.581506Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"%%python --bg --proc infer_proc1\nfrom common_stuff import *\nstart_inference(gpu=1)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:59:33.048124Z","iopub.execute_input":"2025-06-27T19:59:33.048660Z","iopub.status.idle":"2025-06-27T19:59:33.066734Z","shell.execute_reply.started":"2025-06-27T19:59:33.048610Z","shell.execute_reply":"2025-06-27T19:59:33.065632Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"proc_exit_codes = await wait_for_subprocesses(train_proc0, train_proc1, infer_proc0, infer_proc1, print_output=True or arc_test_set.is_fake)\nprint(f'*** Subprocesses exit codes: {proc_exit_codes}')\nassert all(x==0 for x in proc_exit_codes)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T19:59:37.199268Z","iopub.execute_input":"2025-06-27T19:59:37.200615Z","iopub.status.idle":"2025-06-27T20:14:02.986364Z","shell.execute_reply.started":"2025-06-27T19:59:37.200547Z","shell.execute_reply":"2025-06-27T20:14:02.985173Z"},"trusted":true},"outputs":[{"name":"stderr","text":"0. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n1. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n0. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n1. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n1. Unsloth 2024.9.post4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n0. Unsloth 2024.9.post4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"1. *** Load challanges from '/kaggle/input/arc-agi/arc-agi_test_challenges.json'...\n1. *** -> Fake test set detected, setting flag 'is_fake' to True.\n1. *** Load solutions from '/kaggle/input/arc-agi/arc-agi_training_solutions.json'...\n1. *** Load base model and tokenizer from '/kaggle/input/wb55l_nemomini_fulleval/transformers/default/1'...\n1. 🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n1. ==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.44.0.\n1.    \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n1. O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n1. \\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n1.  \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n1. Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n1. *** Create new peft model...\n1. Unsloth: Casting embed_tokens to float32\n1. Unsloth: Casting lm_head to float32\n1. *** Augment dataset...\n1. *** Reducing task size to max. 4224 tokens...\n1.   0%|          | 0/800 [00:00<?, ?it/s]\n1.   8%|▊         | 66/800 [00:00<00:01, 659.33it/s]\n0. *** Load challanges from '/kaggle/input/arc-agi/arc-agi_test_challenges.json'...\n0. *** -> Fake test set detected, setting flag 'is_fake' to True.\n0. *** Load solutions from '/kaggle/input/arc-agi/arc-agi_training_solutions.json'...\n0. *** Load base model and tokenizer from '/kaggle/input/wb55l_nemomini_fulleval/transformers/default/1'...\n0. 🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n0. ==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.44.0.\n0.    \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n0. O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n0. \\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n0.  \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n0. Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n0. *** Create new peft model...\n0. Unsloth: Casting embed_tokens to float32\n0. Unsloth: Casting lm_head to float32\n0. *** Augment dataset...\n0. *** Reducing task size to max. 4224 tokens...\n0.   0%|          | 0/800 [00:00<?, ?it/s]\n1.  16%|█▋        | 132/800 [00:00<00:01, 554.84it/s]\n0.   4%|▍         | 34/800 [00:00<00:02, 323.74it/s]\n1.  24%|██▎       | 189/800 [00:00<00:01, 393.55it/s]\n0.   9%|▉         | 72/800 [00:00<00:02, 355.91it/s]\n1.  29%|██▉       | 233/800 [00:00<00:01, 390.30it/s]\n0.  14%|█▍        | 116/800 [00:00<00:01, 391.83it/s]\n1.  36%|███▌      | 286/800 [00:00<00:01, 428.77it/s]\n0.  20%|█▉        | 156/800 [00:00<00:01, 364.97it/s]\n1.  42%|████▏     | 338/800 [00:00<00:01, 442.81it/s]\n0.  25%|██▌       | 203/800 [00:00<00:01, 396.67it/s]\n1.  51%|█████     | 408/800 [00:00<00:00, 516.23it/s]\n0.  30%|███       | 243/800 [00:00<00:01, 370.94it/s]\n1.  58%|█████▊    | 462/800 [00:00<00:00, 504.64it/s]\n1.  64%|██████▍   | 514/800 [00:01<00:00, 505.49it/s]\n0.  35%|███▌      | 281/800 [00:00<00:01, 370.55it/s]\n0.  40%|███▉      | 319/800 [00:00<00:01, 347.11it/s]\n1.  74%|███████▍  | 590/800 [00:01<00:00, 578.66it/s]\n0.  45%|████▌     | 361/800 [00:00<00:01, 366.47it/s]\n1.  81%|████████▏ | 650/800 [00:01<00:00, 500.89it/s]\n0.  50%|████▉     | 399/800 [00:01<00:01, 340.25it/s]\n1.  88%|████████▊ | 703/800 [00:01<00:00, 465.00it/s]\n0.  54%|█████▍    | 435/800 [00:01<00:01, 345.50it/s]\n1.  94%|█████████▍| 752/800 [00:01<00:00, 458.87it/s]\n1. 100%|██████████| 800/800 [00:01<00:00, 463.80it/s]\n0.  59%|█████▉    | 475/800 [00:01<00:00, 360.68it/s]\n0.  65%|██████▌   | 520/800 [00:01<00:00, 385.08it/s]\n0.  71%|███████   | 566/800 [00:01<00:00, 401.52it/s]\n0.  76%|███████▋  | 610/800 [00:01<00:00, 407.31it/s]\n0.  81%|████████▏ | 651/800 [00:01<00:00, 355.91it/s]\n0.  88%|████████▊ | 701/800 [00:01<00:00, 387.84it/s]\n0.  93%|█████████▎| 741/800 [00:01<00:00, 375.61it/s]\n0.  98%|█████████▊| 785/800 [00:02<00:00, 392.69it/s]\n1. 100%|██████████| 800/800 [00:01<00:00, 475.98it/s]\n","output_type":"stream"},{"name":"stderr","text":"1. Map:   0%|          | 0/800 [00:00<?, ? examples/s]\n1. Map: 100%|██████████| 800/800 [00:00<00:00, 1009.39 examples/s]\n1. Map: 100%|██████████| 800/800 [00:00<00:00, 997.68 examples/s]\n1. max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"},{"name":"stdout","text":"0. 100%|██████████| 800/800 [00:02<00:00, 376.15it/s]\n","output_type":"stream"},{"name":"stderr","text":"0. Map:   0%|          | 0/800 [00:00<?, ? examples/s]\n0. Map: 100%|██████████| 800/800 [00:01<00:00, 733.80 examples/s]\n0. Map: 100%|██████████| 800/800 [00:01<00:00, 729.36 examples/s]\n0. max_steps is given, it will override any value given in num_train_epochs\n1. ==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n1.    \\\\   /|    Num examples = 800 | Num Epochs = 1\n1. O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 2\n1. \\        /    Total batch size = 4 | Total steps = 20\n1.  \"-____-\"     Number of trainable parameters = 188,760,064\n","output_type":"stream"},{"name":"stdout","text":"1. *** Start training run...\n1. *** WARNING: using faulty unsloth gradient accumulation\n1. Unsloth: Setting lr = 1.00e-05 instead of 1.00e-04 for embed_tokens.\n1. Unsloth: Setting lr = 1.00e-05 instead of 1.00e-04 for lm_head.\n","output_type":"stream"},{"name":"stderr","text":"0. ==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n0.    \\\\   /|    Num examples = 800 | Num Epochs = 1\n0. O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 2\n0. \\        /    Total batch size = 4 | Total steps = 20\n0.  \"-____-\"     Number of trainable parameters = 188,760,064\n","output_type":"stream"},{"name":"stdout","text":"0. *** Start training run...\n0. *** WARNING: using faulty unsloth gradient accumulation\n0. Unsloth: Setting lr = 1.00e-05 instead of 1.00e-04 for embed_tokens.\n0. Unsloth: Setting lr = 1.00e-05 instead of 1.00e-04 for lm_head.\n","output_type":"stream"},{"name":"stderr","text":"1.   0%|          | 0/20 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n1.   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n0.   0%|          | 0/20 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n0.   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n1. /opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n1.   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n0. /opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n0.   with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n1.   5%|▌         | 1/20 [00:09<02:59,  9.43s/it]\n0.   5%|▌         | 1/20 [00:09<02:56,  9.27s/it]\n1.  10%|█         | 2/20 [00:19<02:58,  9.94s/it]\n1.  15%|█▌        | 3/20 [00:32<03:07, 11.02s/it]\n0.  10%|█         | 2/20 [00:23<03:40, 12.25s/it]\n1.  20%|██        | 4/20 [00:43<03:01, 11.34s/it]\n0.  15%|█▌        | 3/20 [00:43<04:25, 15.60s/it]\n1.  25%|██▌       | 5/20 [00:55<02:52, 11.51s/it]\n0.  20%|██        | 4/20 [01:00<04:23, 16.44s/it]\n1.  30%|███       | 6/20 [01:07<02:40, 11.50s/it]\n1.  35%|███▌      | 7/20 [01:21<02:42, 12.52s/it]\n0.  25%|██▌       | 5/20 [01:18<04:14, 16.96s/it]\n1.  40%|████      | 8/20 [01:30<02:17, 11.46s/it]\n1.  45%|████▌     | 9/20 [01:41<02:03, 11.22s/it]\n1.  50%|█████     | 10/20 [01:47<01:36,  9.70s/it]\n0.  30%|███       | 6/20 [01:34<03:53, 16.67s/it]\n1.  50%|█████     | 10/20 [01:47<01:36,  9.70s/it]\n0.  35%|███▌      | 7/20 [02:01<04:18, 19.87s/it]\n1.  55%|█████▌    | 11/20 [02:14<02:13, 14.84s/it]\n1.  60%|██████    | 12/20 [02:26<01:52, 14.12s/it]\n0.  40%|████      | 8/20 [02:17<03:45, 18.76s/it]\n1.  65%|██████▌   | 13/20 [02:33<01:22, 11.77s/it]\n0.  45%|████▌     | 9/20 [02:33<03:16, 17.84s/it]\n0.  50%|█████     | 10/20 [02:43<02:33, 15.35s/it]\n1.  70%|███████   | 14/20 [02:39<00:59,  9.97s/it]\n1.  75%|███████▌  | 15/20 [03:04<01:12, 14.56s/it]\n0.  50%|█████     | 10/20 [02:43<02:33, 15.35s/it]\n1.  80%|████████  | 16/20 [03:13<00:51, 12.84s/it]\n0.  55%|█████▌    | 11/20 [03:13<03:00, 20.02s/it]\n0.  60%|██████    | 12/20 [03:30<02:31, 18.99s/it]\n1.  85%|████████▌ | 17/20 [03:29<00:41, 13.96s/it]\n0.  65%|██████▌   | 13/20 [03:38<01:50, 15.75s/it]\n1.  90%|█████████ | 18/20 [03:46<00:29, 14.79s/it]\n1.  95%|█████████▌| 19/20 [04:01<00:14, 14.76s/it]\n1. 100%|██████████| 20/20 [04:12<00:00, 13.69s/it]\n1. 100%|██████████| 20/20 [04:12<00:00, 13.69s/it]\n1. 100%|██████████| 20/20 [04:12<00:00, 13.69s/it]\n1. 100%|██████████| 20/20 [04:12<00:00, 12.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"1. {'loss': 0.0947, 'grad_norm': 1.4297668933868408, 'learning_rate': 9e-06, 'epoch': 0.05}\n1. {'loss': 0.1176, 'grad_norm': 0.9007828235626221, 'learning_rate': 1.9e-05, 'epoch': 0.1}\n1. {'train_runtime': 252.3393, 'train_samples_per_second': 0.317, 'train_steps_per_second': 0.079, 'train_loss': 0.10617158710956573, 'epoch': 0.1}\n1. *** -> Training took 252.3393 seconds.\n1. *** Saving model/tokenizer to '/kaggle/temp/finetuned_model_gpu1'...\n1. *** GPU: Tesla T4, used 9.91 / 14.7 GB.\n","output_type":"stream"},{"name":"stderr","text":"0.  70%|███████   | 14/20 [03:47<01:21, 13.59s/it]\n0.  75%|███████▌  | 15/20 [04:18<01:34, 18.98s/it]\n3. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n3. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n3. Unsloth 2024.9.post4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"3. *** Load challanges from '/kaggle/input/arc-agi/arc-agi_test_challenges.json'...\n3. *** -> Fake test set detected, setting flag 'is_fake' to True.\n3. *** Load solutions from '/kaggle/input/arc-agi/arc-agi_training_solutions.json'...\n3. *** Load base model and tokenizer from '/kaggle/temp/finetuned_model_gpu1'...\n3. 🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n3. ==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.44.0.\n3.    \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n3. O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n3. \\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n3.  \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n3. Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n3. *** Augment dataset...\n3. *** Reducing task size to max. 8192 tokens (7260 input + 932 generated)...\n3.   0%|          | 0/880 [00:00<?, ?it/s]\n3.  20%|██        | 178/880 [00:00<00:00, 1777.64it/s]\n3.  40%|████      | 356/880 [00:00<00:00, 1284.33it/s]\n3.  56%|█████▌    | 493/880 [00:00<00:00, 1030.57it/s]\n3.  69%|██████▊   | 604/880 [00:00<00:00, 876.93it/s]\n3.  79%|███████▉  | 697/880 [00:00<00:00, 764.44it/s]\n3.  88%|████████▊ | 777/880 [00:00<00:00, 597.99it/s]\n3.  96%|█████████▌| 843/880 [00:01<00:00, 487.63it/s]\n3. 100%|██████████| 880/880 [00:01<00:00, 510.24it/s]\n3. *** Load stored data...\n3. *** Start inference run...\n3.   0%|          | 0/5 [00:00<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.03907|0.03907 [0d3d703e_0.transpose.permute9132548760.ex2013.out0]\n3.   0%|          | 0/5 [00:04<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.09590|0.09591 [0d3d703e_0.rot90.permute5764021983.ex0132.out0]\n3.   0%|          | 0/5 [00:04<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:1.59674|1.59681 [0d3d703e_0.transpose.rot90.permute8672310495.ex3012.out0]\n","output_type":"stream"},{"name":"stderr","text":"0.  80%|████████  | 16/20 [04:33<01:10, 17.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"3.   0%|          | 0/5 [00:05<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.68342|0.68343 [0d3d703e_0.transpose.rot90.rot90.permute9146385207.ex0321.out0]\n3.   0%|          | 0/5 [00:06<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 bad_content:1.07405|1.07405 [0d3d703e_0.transpose.rot90.rot90.permute9146385207.ex0321.out1]\n3.   0%|          | 0/5 [00:06<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.04126|0.04126 [0d3d703e_0.rot90.rot90.rot90.permute9208314675.ex2031.out0]\n3.   0%|          | 0/5 [00:07<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02968|0.02969 [0d3d703e_0.transpose.permute8569347012.ex2130.out0]\n3.   0%|          | 0/5 [00:08<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.08725|0.08726 [0d3d703e_0.rot90.permute1384970526.ex1320.out0]\n3.   0%|          | 0/5 [00:09<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 bad_content:1.35312|1.35318 [0d3d703e_0.transpose.rot90.permute4032987651.ex0321.out0]\n3.   0%|          | 0/5 [00:10<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.10593|0.10594 [0d3d703e_0.transpose.rot90.rot90.permute7041952368.ex2310.out0]\n3.   0%|          | 0/5 [00:11<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02309|0.02309 [0d3d703e_0.rot90.rot90.rot90.permute0312769485.ex2130.out0]\n3.   0%|          | 0/5 [00:12<?, ?it/s]\n3.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.80642|0.80648 [0d3d703e_0.transpose.rot90.rot90.rot90.permute8530497126.ex3210.out0]\n3.   0%|          | 0/5 [00:12<?, ?it/s]\n3.  20%|██        | 1/5 [00:12<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01701|0.01702 [25d8a9c8_0.permute0185347962.ex1302.out0]\n3.  20%|██        | 1/5 [00:14<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.14567|0.14574 [25d8a9c8_0.transpose.permute3861705429.ex1302.out0]\n3.  20%|██        | 1/5 [00:15<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.67715|0.68133 [25d8a9c8_0.rot90.permute4872906153.ex0123.out0]\n3.  20%|██        | 1/5 [00:17<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.81386|0.81810 [25d8a9c8_0.rot90.permute4872906153.ex0123.out1]\n3.  20%|██        | 1/5 [00:17<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.04747|0.04749 [25d8a9c8_0.transpose.rot90.permute7981642503.ex0321.out0]\n3.  20%|██        | 1/5 [00:18<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00135|0.00135 [25d8a9c8_0.rot90.rot90.permute0294781653.ex1203.out0]\n3.  20%|██        | 1/5 [00:19<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.46309|0.46343 [25d8a9c8_0.transpose.rot90.rot90.permute0756982341.ex3012.out0]\n3.  20%|██        | 1/5 [00:20<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:1.72090|1.72124 [25d8a9c8_0.transpose.rot90.rot90.permute0756982341.ex3012.out1]\n3.  20%|██        | 1/5 [00:20<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.16465|0.16477 [25d8a9c8_0.rot90.rot90.rot90.permute8521497603.ex1203.out0]\n3.  20%|██        | 1/5 [00:22<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00039|0.00039 [25d8a9c8_0.transpose.rot90.rot90.rot90.permute6457102398.ex1203.out0]\n3.  20%|██        | 1/5 [00:22<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01023|0.01025 [25d8a9c8_0.permute6934175082.ex3102.out0]\n3.  20%|██        | 1/5 [00:22<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.27862|0.27864 [25d8a9c8_0.transpose.permute2561379084.ex3021.out0]\n3.  20%|██        | 1/5 [00:24<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:1.48175|1.48176 [25d8a9c8_0.transpose.permute2561379084.ex3021.out1]\n3.  20%|██        | 1/5 [00:24<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.36146|0.36173 [25d8a9c8_0.rot90.permute8152047936.ex0231.out0]\n3.  20%|██        | 1/5 [00:25<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:1.48644|1.48670 [25d8a9c8_0.rot90.permute8152047936.ex0231.out1]\n3.  20%|██        | 1/5 [00:25<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00180|0.00181 [25d8a9c8_0.transpose.rot90.permute6079328154.ex3102.out0]\n3.  20%|██        | 1/5 [00:26<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00717|0.00718 [25d8a9c8_0.rot90.rot90.permute3947086521.ex0123.out0]\n3.  20%|██        | 1/5 [00:26<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.25718|0.25930 [25d8a9c8_0.transpose.rot90.rot90.permute6021947358.ex0132.out0]\n3.  20%|██        | 1/5 [00:28<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 bad_content:0.22564|0.22588 [25d8a9c8_0.rot90.rot90.rot90.permute9153084627.ex0312.out0]\n3.  20%|██        | 1/5 [00:29<00:49, 12.48s/it]\n3.  acc:   2/  2=99.9% (2-guess),   2/  2=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.29242|0.29247 [25d8a9c8_0.transpose.rot90.rot90.rot90.permute8421630795.ex3102.out0]\n3.  20%|██        | 1/5 [00:30<00:49, 12.48s/it]\n3.  40%|████      | 2/5 [00:30<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.05700|0.05700 [25ff71a9_0.permute9206853714.ex3012.out0]\n3.  40%|████      | 2/5 [00:31<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00321|0.00321 [25ff71a9_0.transpose.permute7296518430.ex3120.out0]\n","output_type":"stream"},{"name":"stderr","text":"0.  85%|████████▌ | 17/20 [04:58<00:59, 19.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"3.  40%|████      | 2/5 [00:32<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01124|0.01125 [25ff71a9_0.rot90.permute8097261354.ex2130.out0]\n3.  40%|████      | 2/5 [00:32<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00112|0.00112 [25ff71a9_0.transpose.rot90.permute9238567041.ex0321.out0]\n3.  40%|████      | 2/5 [00:32<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.11051|0.11053 [25ff71a9_0.rot90.rot90.permute8975420361.ex2103.out0]\n3.  40%|████      | 2/5 [00:33<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00103|0.00104 [25ff71a9_0.transpose.rot90.rot90.permute8046317529.ex1032.out0]\n3.  40%|████      | 2/5 [00:33<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.03857|0.03857 [25ff71a9_0.rot90.rot90.rot90.permute2089157364.ex3210.out0]\n3.  40%|████      | 2/5 [00:34<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.07205|0.07207 [25ff71a9_0.transpose.rot90.rot90.rot90.permute4912085376.ex1023.out0]\n3.  40%|████      | 2/5 [00:34<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 bad_content:0.76118|0.76122 [25ff71a9_0.permute4620798513.ex0123.out0]\n3.  40%|████      | 2/5 [00:35<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:1.54998|1.55001 [25ff71a9_0.permute4620798513.ex0123.out1]\n3.  40%|████      | 2/5 [00:35<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01492|0.01493 [25ff71a9_0.transpose.permute3120459678.ex2103.out0]\n3.  40%|████      | 2/5 [00:36<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02308|0.02309 [25ff71a9_0.rot90.permute2796081354.ex3201.out0]\n3.  40%|████      | 2/5 [00:36<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00632|0.00633 [25ff71a9_0.transpose.rot90.permute3452817690.ex3102.out0]\n3.  40%|████      | 2/5 [00:37<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.03766|0.03767 [25ff71a9_0.rot90.rot90.permute5480123967.ex1302.out0]\n3.  40%|████      | 2/5 [00:37<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00632|0.00633 [25ff71a9_0.transpose.rot90.rot90.permute8045261937.ex1203.out0]\n3.  40%|████      | 2/5 [00:37<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00985|0.00985 [25ff71a9_0.rot90.rot90.rot90.permute1568927430.ex2310.out0]\n3.  40%|████      | 2/5 [00:38<00:46, 15.51s/it]\n3.  acc:   3/  3=99.9% (2-guess),   3/  3=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.07056|0.07058 [25ff71a9_0.transpose.rot90.rot90.rot90.permute6370481259.ex2103.out0]\n3.  40%|████      | 2/5 [00:38<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.30912|0.30915 [25ff71a9_1.permute1762803459.ex1032.out0]\n3.  40%|████      | 2/5 [00:41<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 bad_content:1.38424|1.38428 [25ff71a9_1.permute1762803459.ex1032.out1]\n3.  40%|████      | 2/5 [00:41<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00312|0.00313 [25ff71a9_1.transpose.permute2896147503.ex1302.out0]\n3.  40%|████      | 2/5 [00:41<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.04602|0.04605 [25ff71a9_1.rot90.permute2631987045.ex0123.out0]\n3.  40%|████      | 2/5 [00:42<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02204|0.02204 [25ff71a9_1.transpose.rot90.permute3450192687.ex0231.out0]\n3.  40%|████      | 2/5 [00:42<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.19480|0.19481 [25ff71a9_1.rot90.rot90.permute9243176058.ex3201.out0]\n3.  40%|████      | 2/5 [00:44<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 bad_content:1.74156|1.74157 [25ff71a9_1.rot90.rot90.permute9243176058.ex3201.out1]\n3.  40%|████      | 2/5 [00:44<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01221|0.01221 [25ff71a9_1.transpose.rot90.rot90.permute4908735612.ex0132.out0]\n3.  40%|████      | 2/5 [00:44<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.04813|0.04814 [25ff71a9_1.rot90.rot90.rot90.permute8713495602.ex0213.out0]\n3.  40%|████      | 2/5 [00:44<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.58306|0.58312 [25ff71a9_1.transpose.rot90.rot90.rot90.permute1680392475.ex2310.out0]\n3.  40%|████      | 2/5 [00:46<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 bad_content:0.96340|0.96461 [25ff71a9_1.transpose.rot90.rot90.rot90.permute1680392475.ex2310.out1]\n3.  40%|████      | 2/5 [00:46<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 bad_content:0.66239|0.66243 [25ff71a9_1.permute2054891763.ex0321.out0]\n3.  40%|████      | 2/5 [00:47<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 bad_content:0.95952|0.95956 [25ff71a9_1.permute2054891763.ex0321.out1]\n3.  40%|████      | 2/5 [00:47<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00845|0.00846 [25ff71a9_1.transpose.permute4091873652.ex1230.out0]\n3.  40%|████      | 2/5 [00:47<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.01165|0.01166 [25ff71a9_1.rot90.permute4078361529.ex3102.out0]\n3.  40%|████      | 2/5 [00:48<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.05097|0.05099 [25ff71a9_1.transpose.rot90.permute2683945017.ex2310.out0]\n3.  40%|████      | 2/5 [00:48<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02709|0.02711 [25ff71a9_1.rot90.rot90.permute3690847152.ex3102.out0]\n3.  40%|████      | 2/5 [00:48<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.02011|0.02011 [25ff71a9_1.transpose.rot90.rot90.permute1045962738.ex3201.out0]\n3.  40%|████      | 2/5 [00:49<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.35868|0.35872 [25ff71a9_1.rot90.rot90.rot90.permute6735248910.ex1230.out0]\n3.  40%|████      | 2/5 [00:50<00:46, 15.51s/it]\n3.  acc:   4/  4=99.9% (2-guess),   4/  4=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.09541|0.09549 [25ff71a9_1.transpose.rot90.rot90.rot90.permute7450123869.ex2103.out0]\n3.  40%|████      | 2/5 [00:50<00:46, 15.51s/it]\n3.  60%|██████    | 3/5 [00:50<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00005|0.00006 [3c9b0459_0.permute1548076329.ex2103.out0]\n3.  60%|██████    | 3/5 [00:52<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00003|0.00003 [3c9b0459_0.transpose.permute0742586913.ex3021.out0]\n3.  60%|██████    | 3/5 [00:52<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00011|0.00011 [3c9b0459_0.rot90.permute9184520673.ex1203.out0]\n3.  60%|██████    | 3/5 [00:53<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00045|0.00046 [3c9b0459_0.transpose.rot90.permute8096742315.ex3012.out0]\n3.  60%|██████    | 3/5 [00:53<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00037|0.00037 [3c9b0459_0.rot90.rot90.permute7054189263.ex0231.out0]\n3.  60%|██████    | 3/5 [00:53<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00071|0.00072 [3c9b0459_0.transpose.rot90.rot90.permute3942051768.ex3102.out0]\n3.  60%|██████    | 3/5 [00:54<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00008|0.00008 [3c9b0459_0.rot90.rot90.rot90.permute9017823645.ex1302.out0]\n3.  60%|██████    | 3/5 [00:54<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00373|0.00374 [3c9b0459_0.transpose.rot90.rot90.rot90.permute4201579863.ex3021.out0]\n3.  60%|██████    | 3/5 [00:55<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00185|0.00186 [3c9b0459_0.permute3245179608.ex0312.out0]\n3.  60%|██████    | 3/5 [00:55<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00003|0.00003 [3c9b0459_0.transpose.permute2096517483.ex1320.out0]\n3.  60%|██████    | 3/5 [00:55<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00006|0.00006 [3c9b0459_0.rot90.permute0341257869.ex2130.out0]\n3.  60%|██████    | 3/5 [00:56<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00022|0.00022 [3c9b0459_0.transpose.rot90.permute2953841607.ex1320.out0]\n3.  60%|██████    | 3/5 [00:56<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00005|0.00006 [3c9b0459_0.rot90.rot90.permute3270985461.ex0213.out0]\n","output_type":"stream"},{"name":"stderr","text":"0.  90%|█████████ | 18/20 [05:24<00:43, 21.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"3.  60%|██████    | 3/5 [00:57<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00006|0.00006 [3c9b0459_0.transpose.rot90.rot90.permute8407362159.ex3210.out0]\n3.  60%|██████    | 3/5 [00:57<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00020|0.00021 [3c9b0459_0.rot90.rot90.rot90.permute3496817025.ex0123.out0]\n3.  60%|██████    | 3/5 [00:57<00:35, 17.78s/it]\n3.  acc:   5/  5=99.9% (2-guess),   5/  5=99.9% (any); tok: 191+ 14> 14 ALL_CORRECT:0.00458|0.00458 [3c9b0459_0.transpose.rot90.rot90.rot90.permute3920517486.ex0312.out0]\n3.  60%|██████    | 3/5 [00:58<00:35, 17.78s/it]\n3.  80%|████████  | 4/5 [00:58<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.68697|0.68702 [27a28665_0.permute8257319046.ex0631452.out0]\n3.  80%|████████  | 4/5 [00:59<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.96822|0.96827 [27a28665_0.permute8257319046.ex0631452.out1]\n3.  80%|████████  | 4/5 [00:59<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.42832|0.42836 [27a28665_0.transpose.permute5629138470.ex4136025.out0]\n3.  80%|████████  | 4/5 [00:59<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.74082|1.74086 [27a28665_0.transpose.permute5629138470.ex4136025.out1]\n3.  80%|████████  | 4/5 [00:59<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.36387|0.36389 [27a28665_0.rot90.permute0948263157.ex6421503.out0]\n3.  80%|████████  | 4/5 [01:00<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.43808|1.43812 [27a28665_0.rot90.permute0948263157.ex6421503.out1]\n3.  80%|████████  | 4/5 [01:00<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.25224|0.25226 [27a28665_0.transpose.rot90.permute1745239680.ex5034621.out0]\n3.  80%|████████  | 4/5 [01:00<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.61158|0.61163 [27a28665_0.rot90.rot90.permute0476951382.ex0625134.out0]\n3.  80%|████████  | 4/5 [01:01<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.22877|1.22882 [27a28665_0.rot90.rot90.permute0476951382.ex0625134.out1]\n3.  80%|████████  | 4/5 [01:01<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.68593|0.68597 [27a28665_0.transpose.rot90.rot90.permute6019845237.ex2564031.out0]\n3.  80%|████████  | 4/5 [01:02<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.78750|0.78753 [27a28665_0.transpose.rot90.rot90.permute6019845237.ex2564031.out1]\n3.  80%|████████  | 4/5 [01:02<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.70398|0.70405 [27a28665_0.rot90.rot90.rot90.permute8452731960.ex3421506.out0]\n3.  80%|████████  | 4/5 [01:02<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.21570|1.21577 [27a28665_0.rot90.rot90.rot90.permute8452731960.ex3421506.out1]\n3.  80%|████████  | 4/5 [01:02<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.07333|0.07334 [27a28665_0.transpose.rot90.rot90.rot90.permute3694028715.ex2053164.out0]\n3.  80%|████████  | 4/5 [01:03<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.61480|0.61486 [27a28665_0.permute2348716095.ex4361250.out0]\n3.  80%|████████  | 4/5 [01:04<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.29839|1.29846 [27a28665_0.permute2348716095.ex4361250.out1]\n3.  80%|████████  | 4/5 [01:04<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.62281|0.62290 [27a28665_0.transpose.permute6314970528.ex6241350.out0]\n3.  80%|████████  | 4/5 [01:05<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.50172|1.50180 [27a28665_0.transpose.permute6314970528.ex6241350.out1]\n3.  80%|████████  | 4/5 [01:05<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.69703|1.69714 [27a28665_0.transpose.permute6314970528.ex6241350.out2]\n3.  80%|████████  | 4/5 [01:05<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.71179|0.71188 [27a28665_0.rot90.permute3861504297.ex4102365.out0]\n3.  80%|████████  | 4/5 [01:06<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.53210|1.53219 [27a28665_0.rot90.permute3861504297.ex4102365.out1]\n3.  80%|████████  | 4/5 [01:06<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.72351|1.72360 [27a28665_0.rot90.permute3861504297.ex4102365.out2]\n3.  80%|████████  | 4/5 [01:06<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.27832|0.27837 [27a28665_0.transpose.rot90.permute2576908143.ex0431265.out0]\n3.  80%|████████  | 4/5 [01:06<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.56617|0.56622 [27a28665_0.rot90.rot90.permute4209781563.ex5423610.out0]\n3.  80%|████████  | 4/5 [01:07<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:1.59742|1.59750 [27a28665_0.rot90.rot90.permute4209781563.ex5423610.out1]\n3.  80%|████████  | 4/5 [01:07<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.10927|0.10929 [27a28665_0.transpose.rot90.rot90.permute5194638720.ex3645012.out0]\n3.  80%|████████  | 4/5 [01:08<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 bad_content:0.08861|0.08862 [27a28665_0.rot90.rot90.rot90.permute2385409167.ex5016243.out0]\n3.  80%|████████  | 4/5 [01:08<00:13, 13.79s/it]\n3.  acc:   6/  6=99.9% (2-guess),   6/  6=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.06418|0.06419 [27a28665_0.transpose.rot90.rot90.rot90.permute5730148926.ex0523164.out0]\n3.  80%|████████  | 4/5 [01:09<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.66335|1.66352 [27a28665_1.permute0526374189.ex5260431.out0]\n3.  80%|████████  | 4/5 [01:09<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.29106|1.29114 [27a28665_1.transpose.permute8694503217.ex0652431.out0]\n3.  80%|████████  | 4/5 [01:10<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.68168|1.68178 [27a28665_1.transpose.permute8694503217.ex0652431.out1]\n3.  80%|████████  | 4/5 [01:10<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.74418|1.74442 [27a28665_1.transpose.permute8694503217.ex0652431.out2]\n3.  80%|████████  | 4/5 [01:10<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.37615|1.37651 [27a28665_1.rot90.permute3461827905.ex0364215.out0]\n3.  80%|████████  | 4/5 [01:11<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.60560|1.60577 [27a28665_1.transpose.rot90.permute2371985460.ex3541260.out0]\n3.  80%|████████  | 4/5 [01:11<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.62123|1.62138 [27a28665_1.transpose.rot90.permute2371985460.ex3541260.out1]\n3.  80%|████████  | 4/5 [01:11<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.56742|1.56760 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out0]\n3.  80%|████████  | 4/5 [01:12<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.61039|1.61056 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out1]\n3.  80%|████████  | 4/5 [01:12<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.76273|1.76291 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out2]\n3.  80%|████████  | 4/5 [01:12<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.08436|1.08459 [27a28665_1.transpose.rot90.rot90.permute2641509873.ex2360145.out0]\n3.  80%|████████  | 4/5 [01:13<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.45546|1.45570 [27a28665_1.transpose.rot90.rot90.permute2641509873.ex2360145.out1]\n3.  80%|████████  | 4/5 [01:13<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.06636|1.06649 [27a28665_1.rot90.rot90.rot90.permute1927360458.ex3506142.out0]\n","output_type":"stream"},{"name":"stderr","text":"0.  95%|█████████▌| 19/20 [05:49<00:22, 22.63s/it]\n0. 100%|██████████| 20/20 [06:06<00:00, 20.97s/it]\n0. 100%|██████████| 20/20 [06:06<00:00, 20.97s/it]\n0. 100%|██████████| 20/20 [06:06<00:00, 20.97s/it]\n0. 100%|██████████| 20/20 [06:06<00:00, 18.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"3.  80%|████████  | 4/5 [01:14<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.75857|1.75905 [27a28665_1.transpose.rot90.rot90.rot90.permute8263471095.ex2136045.out0]\n3.  80%|████████  | 4/5 [01:14<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.73291|1.73331 [27a28665_1.permute4315762098.ex3405126.out0]\n3.  80%|████████  | 4/5 [01:15<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:0.65056|0.65072 [27a28665_1.transpose.permute2103984576.ex3560124.out0]\n3.  80%|████████  | 4/5 [01:15<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:0.56978|0.56991 [27a28665_1.rot90.permute9538401672.ex3521460.out0]\n3.  80%|████████  | 4/5 [01:16<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:0.23239|0.23248 [27a28665_1.transpose.rot90.permute5490731286.ex5302164.out0]\n0. {'loss': 0.0522, 'grad_norm': 0.9655558466911316, 'learning_rate': 1e-05, 'epoch': 0.05}\n0. {'loss': 0.0446, 'grad_norm': 0.5570511221885681, 'learning_rate': 1.9e-05, 'epoch': 0.1}\n0. {'train_runtime': 366.4426, 'train_samples_per_second': 0.218, 'train_steps_per_second': 0.055, 'train_loss': 0.04840528815984726, 'epoch': 0.1}\n0. *** -> Training took 366.4426 seconds.\n0. *** Saving model/tokenizer to '/kaggle/temp/finetuned_model_gpu0'...\n0. *** GPU: Tesla T4, used 9.95 / 14.7 GB.\n3.  80%|████████  | 4/5 [01:16<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.38987|1.39024 [27a28665_1.rot90.rot90.permute4087162539.ex5326401.out0]\n3.  80%|████████  | 4/5 [01:17<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.71409|1.71436 [27a28665_1.rot90.rot90.permute4087162539.ex5326401.out1]\n3.  80%|████████  | 4/5 [01:17<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   6/  7=85.7% (any); tok: 214+  4>  4 bad_content:1.19262|1.19282 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out0]\n3.  80%|████████  | 4/5 [01:18<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.61449|1.61471 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out1]\n3.  80%|████████  | 4/5 [01:18<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 bad_content:1.69652|1.69673 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out2]\n3.  80%|████████  | 4/5 [01:18<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 bad_content:1.41830|1.41850 [27a28665_1.rot90.rot90.rot90.permute8634120759.ex2463015.out0]\n3.  80%|████████  | 4/5 [01:19<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.76986|1.77003 [27a28665_1.rot90.rot90.rot90.permute8634120759.ex2463015.out1]\n3.  80%|████████  | 4/5 [01:19<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 bad_content:0.68692|0.68709 [27a28665_1.transpose.rot90.rot90.rot90.permute5304781296.ex5231604.out0]\n3.  80%|████████  | 4/5 [01:19<00:13, 13.79s/it]\n3.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.12442|1.12475 [27a28665_1.transpose.rot90.rot90.rot90.permute5304781296.ex5231604.out1]\n3.  80%|████████  | 4/5 [01:19<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:0.98935|0.98987 [27a28665_2.permute4813052976.ex1526034.out0]\n3.  80%|████████  | 4/5 [01:20<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:0.90651|0.90659 [27a28665_2.transpose.permute5963817024.ex2415306.out0]\n3.  80%|████████  | 4/5 [01:20<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.72292|1.72384 [27a28665_2.transpose.permute5963817024.ex2415306.out1]\n3.  80%|████████  | 4/5 [01:20<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.32910|1.32925 [27a28665_2.transpose.rot90.permute3752061489.ex4305261.out0]\n3.  80%|████████  | 4/5 [01:22<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.68573|1.68591 [27a28665_2.rot90.rot90.permute0591328467.ex0125364.out0]\n3.  80%|████████  | 4/5 [01:22<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.35299|1.35316 [27a28665_2.transpose.rot90.rot90.permute8273406195.ex2530461.out0]\n3.  80%|████████  | 4/5 [01:23<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.05802|1.05820 [27a28665_2.rot90.rot90.rot90.permute2893741065.ex5134062.out0]\n3.  80%|████████  | 4/5 [01:23<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.69847|1.69865 [27a28665_2.transpose.rot90.rot90.rot90.permute6894501327.ex3240651.out0]\n3.  80%|████████  | 4/5 [01:24<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.75706|1.75722 [27a28665_2.transpose.rot90.rot90.rot90.permute6894501327.ex3240651.out1]\n3.  80%|████████  | 4/5 [01:24<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:0.93326|0.93345 [27a28665_2.permute8705426193.ex0326154.out0]\n3.  80%|████████  | 4/5 [01:24<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.23786|1.23803 [27a28665_2.rot90.permute7239864105.ex1530462.out0]\n3.  80%|████████  | 4/5 [01:26<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.45661|1.45684 [27a28665_2.rot90.permute7239864105.ex1530462.out1]\n3.  80%|████████  | 4/5 [01:26<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.55817|1.55836 [27a28665_2.rot90.permute7239864105.ex1530462.out2]\n3.  80%|████████  | 4/5 [01:26<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.25289|1.25375 [27a28665_2.transpose.rot90.permute3618725490.ex2306415.out0]\n3.  80%|████████  | 4/5 [01:26<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:1.63996|1.64012 [27a28665_2.rot90.rot90.permute6518427093.ex3245601.out0]\n3.  80%|████████  | 4/5 [01:27<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.70636|1.70773 [27a28665_2.rot90.rot90.permute6518427093.ex3245601.out1]\n3.  80%|████████  | 4/5 [01:27<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 bad_content:0.74839|0.74851 [27a28665_2.transpose.rot90.rot90.permute3215690874.ex3412506.out0]\n3.  80%|████████  | 4/5 [01:28<00:13, 13.79s/it]\n3.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 214+  4>  4 ALL_CORRECT:1.48276|1.48316 [27a28665_2.transpose.rot90.rot90.permute3215690874.ex3412506.out1]\n3.  80%|████████  | 4/5 [01:28<00:13, 13.79s/it]\n3. 100%|██████████| 5/5 [01:28<00:00, 19.84s/it]\n3. 100%|██████████| 5/5 [01:28<00:00, 17.77s/it]\n3. *** Completed inference run.\n3. calculate augmented scores:   0%|          | 0/8 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stderr","text":"2. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n2. Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"3. calculate augmented scores:  12%|█▎        | 1/8 [00:09<01:09,  9.91s/it]\n","output_type":"stream"},{"name":"stderr","text":"2. Unsloth 2024.9.post4 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"2. *** Load challanges from '/kaggle/input/arc-agi/arc-agi_test_challenges.json'...\n2. *** -> Fake test set detected, setting flag 'is_fake' to True.\n2. *** Load solutions from '/kaggle/input/arc-agi/arc-agi_training_solutions.json'...\n2. *** Load base model and tokenizer from '/kaggle/temp/finetuned_model_gpu0'...\n2. 🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n2. ==((====))==  Unsloth 2024.9.post4: Fast Mistral patching. Transformers = 4.44.0.\n2.    \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n2. O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n2. \\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n2.  \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n2. Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n2. *** Augment dataset...\n2. *** Reducing task size to max. 8192 tokens (7260 input + 932 generated)...\n2.   0%|          | 0/800 [00:00<?, ?it/s]\n2.  16%|█▌        | 125/800 [00:00<00:00, 1244.50it/s]\n2.  31%|███▏      | 250/800 [00:00<00:00, 898.44it/s]\n2.  43%|████▎     | 346/800 [00:00<00:00, 745.96it/s]\n2.  53%|█████▎    | 425/800 [00:00<00:00, 646.31it/s]\n2.  62%|██████▏   | 493/800 [00:00<00:00, 556.43it/s]\n2.  69%|██████▉   | 551/800 [00:00<00:00, 487.87it/s]\n3. calculate augmented scores:  25%|██▌       | 2/8 [00:19<00:59, 10.00s/it]\n2.  75%|███████▌  | 602/800 [00:01<00:00, 435.77it/s]\n2.  81%|████████  | 647/800 [00:01<00:00, 385.54it/s]\n2.  86%|████████▌ | 687/800 [00:01<00:00, 345.77it/s]\n2.  90%|█████████ | 723/800 [00:01<00:00, 302.08it/s]\n2.  94%|█████████▍| 754/800 [00:01<00:00, 257.19it/s]\n2.  98%|█████████▊| 781/800 [00:01<00:00, 211.20it/s]\n2. 100%|██████████| 800/800 [00:02<00:00, 373.34it/s]\n2. *** Load stored data...\n2. *** Start inference run...\n2.   0%|          | 0/8 [00:00<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.permute8150729436.ex012.out0]\n2.   0%|          | 0/8 [00:03<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.permute5012869347.ex210.out0]\n2.   0%|          | 0/8 [00:04<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00024|0.00024 [0520fde7_0.rot90.permute1504397682.ex120.out0]\n2.   0%|          | 0/8 [00:04<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00005|0.00005 [0520fde7_0.transpose.rot90.permute6597130824.ex012.out0]\n2.   0%|          | 0/8 [00:04<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00002|0.00002 [0520fde7_0.rot90.rot90.permute5274316980.ex210.out0]\n2.   0%|          | 0/8 [00:05<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00008|0.00008 [0520fde7_0.transpose.rot90.rot90.permute1679452803.ex012.out0]\n2.   0%|          | 0/8 [00:05<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00599|0.00599 [0520fde7_0.rot90.rot90.rot90.permute0372196854.ex021.out0]\n2.   0%|          | 0/8 [00:06<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.rot90.rot90.rot90.permute7289501634.ex120.out0]\n2.   0%|          | 0/8 [00:06<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00002|0.00002 [0520fde7_0.permute2874513906.ex210.out0]\n2.   0%|          | 0/8 [00:06<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.permute4156892370.ex120.out0]\n2.   0%|          | 0/8 [00:07<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00070|0.00070 [0520fde7_0.rot90.permute6314970528.ex210.out0]\n2.   0%|          | 0/8 [00:07<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00000|0.00000 [0520fde7_0.transpose.rot90.permute1384970526.ex012.out0]\n2.   0%|          | 0/8 [00:08<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.rot90.rot90.permute8217503946.ex102.out0]\n2.   0%|          | 0/8 [00:08<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00000|0.00000 [0520fde7_0.transpose.rot90.rot90.permute3128906475.ex021.out0]\n2.   0%|          | 0/8 [00:09<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 224+ 14> 14 ALL_CORRECT:0.00131|0.00131 [0520fde7_0.rot90.rot90.rot90.permute6498012573.ex201.out0]\n2.   0%|          | 0/8 [00:09<?, ?it/s]\n2.  acc:   1/  1=99.9% (2-guess),   1/  1=99.9% (any); tok: 208+ 14> 14 ALL_CORRECT:0.00241|0.00242 [0520fde7_0.transpose.rot90.rot90.rot90.permute3290157684.ex102.out0]\n2.   0%|          | 0/8 [00:09<?, ?it/s]\n3. calculate augmented scores:  38%|███▊      | 3/8 [00:26<00:42,  8.47s/it]\n2.  12%|█▎        | 1/8 [00:09<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   1/  2=50.0% (any); tok: 290+ 32> 32 bad_content:1.49243|1.49244 [1e0a9b12_0.permute0185347962.ex120.out0]\n2.  12%|█▎        | 1/8 [00:16<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   1/  2=50.0% (any); tok: 290+ 32> 32 bad_content:1.49608|1.49611 [1e0a9b12_0.permute0185347962.ex120.out1]\n2.  12%|█▎        | 1/8 [00:16<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:1.63314|1.63316 [1e0a9b12_0.permute0185347962.ex120.out2]\n2.  12%|█▎        | 1/8 [00:16<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.05802|0.05803 [1e0a9b12_0.transpose.permute0857149623.ex210.out0]\n2.  12%|█▎        | 1/8 [00:17<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.00111|0.00111 [1e0a9b12_0.rot90.permute7630598412.ex021.out0]\n3. calculate augmented scores:  50%|█████     | 4/8 [00:43<00:46, 11.67s/it]\n2.  12%|█▎        | 1/8 [00:18<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.03398|0.03398 [1e0a9b12_0.transpose.rot90.permute9021654837.ex120.out0]\n2.  12%|█▎        | 1/8 [00:21<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.39840|0.39843 [1e0a9b12_0.rot90.rot90.permute8473016925.ex012.out0]\n2.  12%|█▎        | 1/8 [00:23<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:1.39780|1.39782 [1e0a9b12_0.rot90.rot90.permute8473016925.ex012.out1]\n2.  12%|█▎        | 1/8 [00:23<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.00417|0.00417 [1e0a9b12_0.transpose.rot90.rot90.permute2734605819.ex012.out0]\n2.  12%|█▎        | 1/8 [00:23<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.03246|0.03246 [1e0a9b12_0.rot90.rot90.rot90.permute3275198046.ex210.out0]\n2.  12%|█▎        | 1/8 [00:24<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.58250|0.58252 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute4239705681.ex201.out0]\n2.  12%|█▎        | 1/8 [00:27<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:1.53615|1.53617 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute4239705681.ex201.out1]\n2.  12%|█▎        | 1/8 [00:27<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.60257|0.60258 [1e0a9b12_0.permute6870592413.ex210.out0]\n2.  12%|█▎        | 1/8 [00:31<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:1.26334|1.26336 [1e0a9b12_0.permute6870592413.ex210.out1]\n3. calculate augmented scores:  62%|██████▎   | 5/8 [00:46<00:25,  8.65s/it]\n2.  12%|█▎        | 1/8 [00:31<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.47919|0.47920 [1e0a9b12_0.transpose.permute5910762348.ex210.out0]\n2.  12%|█▎        | 1/8 [00:34<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.98098|0.98098 [1e0a9b12_0.transpose.permute5910762348.ex210.out1]\n2.  12%|█▎        | 1/8 [00:34<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.00046|0.00046 [1e0a9b12_0.rot90.permute2103984576.ex210.out0]\n2.  12%|█▎        | 1/8 [00:35<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.02266|0.02266 [1e0a9b12_0.transpose.rot90.permute8152047936.ex120.out0]\n2.  12%|█▎        | 1/8 [00:37<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.61446|0.61447 [1e0a9b12_0.rot90.rot90.permute0594736812.ex021.out0]\n2.  12%|█▎        | 1/8 [00:39<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.78697|0.78698 [1e0a9b12_0.rot90.rot90.permute0594736812.ex021.out1]\n2.  12%|█▎        | 1/8 [00:39<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.00061|0.00061 [1e0a9b12_0.transpose.rot90.rot90.permute8317290645.ex102.out0]\n2.  12%|█▎        | 1/8 [00:40<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 ALL_CORRECT:0.00330|0.00330 [1e0a9b12_0.rot90.rot90.rot90.permute2085176934.ex120.out0]\n2.  12%|█▎        | 1/8 [00:40<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:0.97176|0.97179 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute6857219340.ex021.out0]\n2.  12%|█▎        | 1/8 [00:44<01:09,  9.90s/it]\n2.  acc:   1/  2=50.0% (2-guess),   2/  2=99.9% (any); tok: 290+ 32> 32 bad_content:1.37294|1.37297 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute6857219340.ex021.out1]\n2.  12%|█▎        | 1/8 [00:44<01:09,  9.90s/it]\n3. calculate augmented scores:  75%|███████▌  | 6/8 [00:59<00:20, 10.26s/it]\n2.  25%|██▌       | 2/8 [00:44<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.02829|0.02829 [3af2c5a8_0.permute9206853714.ex012.out0]\n2.  25%|██▌       | 2/8 [00:50<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.03336|0.03336 [3af2c5a8_0.transpose.permute8451396702.ex210.out0]\n2.  25%|██▌       | 2/8 [00:51<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.00049|0.00049 [3af2c5a8_0.rot90.permute3216708459.ex021.out0]\n2.  25%|██▌       | 2/8 [00:51<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00041|0.00041 [3af2c5a8_0.transpose.rot90.permute7352408961.ex012.out0]\n2.  25%|██▌       | 2/8 [00:52<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00143|0.00143 [3af2c5a8_0.rot90.rot90.permute0928167354.ex012.out0]\n2.  25%|██▌       | 2/8 [00:52<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 bad_content:0.24809|0.24811 [3af2c5a8_0.transpose.rot90.rot90.permute7513206948.ex120.out0]\n2.  25%|██▌       | 2/8 [00:54<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:1.65425|1.65429 [3af2c5a8_0.transpose.rot90.rot90.permute7513206948.ex120.out1]\n2.  25%|██▌       | 2/8 [00:54<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.00659|0.00665 [3af2c5a8_0.rot90.rot90.rot90.permute5862037914.ex120.out0]\n2.  25%|██▌       | 2/8 [00:55<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00037|0.00037 [3af2c5a8_0.transpose.rot90.rot90.rot90.permute7236948015.ex012.out0]\n2.  25%|██▌       | 2/8 [00:56<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00365|0.00365 [3af2c5a8_0.permute3857410629.ex021.out0]\n2.  25%|██▌       | 2/8 [00:56<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.00255|0.00255 [3af2c5a8_0.transpose.permute9182036754.ex120.out0]\n2.  25%|██▌       | 2/8 [00:57<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.00059|0.00059 [3af2c5a8_0.rot90.permute4382705916.ex210.out0]\n2.  25%|██▌       | 2/8 [00:57<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00012|0.00012 [3af2c5a8_0.transpose.rot90.permute2796081354.ex210.out0]\n2.  25%|██▌       | 2/8 [00:58<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00071|0.00071 [3af2c5a8_0.rot90.rot90.permute6028439751.ex201.out0]\n2.  25%|██▌       | 2/8 [00:58<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.50290|0.50291 [3af2c5a8_0.transpose.rot90.rot90.permute2376841590.ex120.out0]\n2.  25%|██▌       | 2/8 [01:00<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 bad_content:0.94418|0.94418 [3af2c5a8_0.transpose.rot90.rot90.permute2376841590.ex120.out1]\n2.  25%|██▌       | 2/8 [01:00<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 308+ 58> 58 ALL_CORRECT:0.00900|0.00900 [3af2c5a8_0.rot90.rot90.rot90.permute0248369571.ex012.out0]\n3. calculate augmented scores:  88%|████████▊ | 7/8 [01:16<00:12, 12.37s/it]\n3. calculate augmented scores: 100%|██████████| 8/8 [01:29<00:00, 12.68s/it]\n3. calculate augmented scores: 100%|██████████| 8/8 [01:29<00:00, 11.24s/it]\n3. *** GPU: Tesla T4, used 5.18 / 14.7 GB.\n2.  25%|██▌       | 2/8 [01:01<02:25, 24.20s/it]\n2.  acc:   2/  3=66.7% (2-guess),   3/  3=99.9% (any); tok: 298+ 56> 56 ALL_CORRECT:0.00021|0.00021 [3af2c5a8_0.transpose.rot90.rot90.rot90.permute5264931807.ex012.out0]\n2.  25%|██▌       | 2/8 [01:01<02:25, 24.20s/it]\n2.  38%|███▊      | 3/8 [01:01<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.permute1762803459.ex10.out0]\n2.  38%|███▊      | 3/8 [01:10<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00020|0.00021 [3ac3eb23_0.transpose.permute2187306594.ex10.out0]\n2.  38%|███▊      | 3/8 [01:11<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00004|0.00004 [3ac3eb23_0.rot90.permute7368249501.ex10.out0]\n2.  38%|███▊      | 3/8 [01:12<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.48057|0.48059 [3ac3eb23_0.transpose.rot90.permute5672940813.ex01.out0]\n2.  38%|███▊      | 3/8 [01:20<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 bad_content:1.56074|1.56079 [3ac3eb23_0.transpose.rot90.permute5672940813.ex01.out1]\n2.  38%|███▊      | 3/8 [01:20<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.36757|0.36759 [3ac3eb23_0.rot90.rot90.permute4236781950.ex10.out0]\n2.  38%|███▊      | 3/8 [01:29<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 bad_content:1.38630|1.38636 [3ac3eb23_0.rot90.rot90.permute4236781950.ex10.out1]\n2.  38%|███▊      | 3/8 [01:29<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.transpose.rot90.rot90.permute8604172935.ex01.out0]\n2.  38%|███▊      | 3/8 [01:30<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.41632|0.41634 [3ac3eb23_0.rot90.rot90.rot90.permute0285196734.ex01.out0]\n2.  38%|███▊      | 3/8 [01:34<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.transpose.rot90.rot90.rot90.permute0365427918.ex10.out0]\n2.  38%|███▊      | 3/8 [01:35<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.permute4837605912.ex10.out0]\n2.  38%|███▊      | 3/8 [01:36<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00061|0.00062 [3ac3eb23_0.transpose.permute8594670321.ex10.out0]\n2.  38%|███▊      | 3/8 [01:36<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00001|0.00001 [3ac3eb23_0.rot90.permute4165297308.ex01.out0]\n2.  38%|███▊      | 3/8 [01:37<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.31054|0.31058 [3ac3eb23_0.transpose.rot90.permute4078361529.ex01.out0]\n2.  38%|███▊      | 3/8 [01:45<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 bad_content:1.43413|1.43418 [3ac3eb23_0.transpose.rot90.permute4078361529.ex01.out1]\n2.  38%|███▊      | 3/8 [01:45<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.56252|0.56255 [3ac3eb23_0.rot90.rot90.permute5061423978.ex01.out0]\n2.  38%|███▊      | 3/8 [01:54<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 bad_content:0.95651|0.95656 [3ac3eb23_0.rot90.rot90.permute5061423978.ex01.out1]\n2.  38%|███▊      | 3/8 [01:54<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.00005|0.00005 [3ac3eb23_0.transpose.rot90.rot90.permute1308647925.ex01.out0]\n2.  38%|███▊      | 3/8 [01:55<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 ALL_CORRECT:0.39904|0.39905 [3ac3eb23_0.rot90.rot90.rot90.permute2107946853.ex10.out0]\n2.  38%|███▊      | 3/8 [02:04<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 391+ 86> 86 bad_content:1.61014|1.61015 [3ac3eb23_0.rot90.rot90.rot90.permute2107946853.ex10.out1]\n2.  38%|███▊      | 3/8 [02:04<01:46, 21.31s/it]\n2.  acc:   3/  4=75.0% (2-guess),   4/  4=99.9% (any); tok: 375+ 80> 80 ALL_CORRECT:0.00004|0.00004 [3ac3eb23_0.transpose.rot90.rot90.rot90.permute9175426038.ex01.out0]\n2.  38%|███▊      | 3/8 [02:05<01:46, 21.31s/it]\n2.  50%|█████     | 4/8 [02:05<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00022|0.00022 [29c11459_0.permute1548076329.ex10.out0]\n2.  50%|█████     | 4/8 [02:12<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.01188|0.01189 [29c11459_0.transpose.permute7243851609.ex10.out0]\n2.  50%|█████     | 4/8 [02:13<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.02077|0.02077 [29c11459_0.rot90.permute3710429658.ex01.out0]\n2.  50%|█████     | 4/8 [02:13<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00036|0.00036 [29c11459_0.transpose.rot90.permute8940537621.ex10.out0]\n2.  50%|█████     | 4/8 [02:14<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00117|0.00117 [29c11459_0.rot90.rot90.permute8027346591.ex01.out0]\n2.  50%|█████     | 4/8 [02:15<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.08253|0.08254 [29c11459_0.transpose.rot90.rot90.permute1397508426.ex10.out0]\n2.  50%|█████     | 4/8 [02:15<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.04605|0.04606 [29c11459_0.rot90.rot90.rot90.permute5896340271.ex01.out0]\n2.  50%|█████     | 4/8 [02:16<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00012|0.00012 [29c11459_0.transpose.rot90.rot90.rot90.permute4068123597.ex01.out0]\n2.  50%|█████     | 4/8 [02:17<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00007|0.00007 [29c11459_0.permute0673298145.ex01.out0]\n2.  50%|█████     | 4/8 [02:18<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.05252|0.05252 [29c11459_0.transpose.permute4598260713.ex10.out0]\n2.  50%|█████     | 4/8 [02:18<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.02146|0.02147 [29c11459_0.rot90.permute1547328690.ex10.out0]\n2.  50%|█████     | 4/8 [02:19<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00008|0.00008 [29c11459_0.transpose.rot90.permute0341257869.ex10.out0]\n2.  50%|█████     | 4/8 [02:20<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00093|0.00093 [29c11459_0.rot90.rot90.permute9251687430.ex10.out0]\n2.  50%|█████     | 4/8 [02:20<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.00568|0.00568 [29c11459_0.transpose.rot90.rot90.permute8061953274.ex01.out0]\n2.  50%|█████     | 4/8 [02:21<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 399+ 68> 68 ALL_CORRECT:0.02810|0.02810 [29c11459_0.rot90.rot90.rot90.permute6794251830.ex10.out0]\n2.  50%|█████     | 4/8 [02:22<02:31, 37.96s/it]\n2.  acc:   4/  5=80.0% (2-guess),   5/  5=99.9% (any); tok: 369+ 62> 62 ALL_CORRECT:0.00012|0.00012 [29c11459_0.transpose.rot90.rot90.rot90.permute5947062381.ex01.out0]\n2.  50%|█████     | 4/8 [02:23<02:31, 37.96s/it]\n2.  62%|██████▎   | 5/8 [02:23<01:31, 30.63s/it]\n2.  acc:   4/  6=66.7% (2-guess),   5/  6=83.3% (any); tok: 423+ 14> 14 bad_content:0.56419|0.62906 [2013d3e2_0.permute8257319046.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:26<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:1.41621|1.74301 [2013d3e2_0.permute8257319046.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:26<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.05421|0.06684 [2013d3e2_0.transpose.permute9132548760.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:27<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.03951|0.03956 [2013d3e2_0.rot90.permute1856342970.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:28<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.36345|0.36351 [2013d3e2_0.transpose.rot90.permute0579623418.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:29<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.45720|1.45725 [2013d3e2_0.transpose.rot90.permute0579623418.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:29<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:0.60322|0.60343 [2013d3e2_0.rot90.rot90.permute9517802463.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:30<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.30223|1.33578 [2013d3e2_0.transpose.rot90.rot90.permute1570324869.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:31<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.18968|0.18987 [2013d3e2_0.rot90.rot90.rot90.permute3219567804.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:32<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.78193|0.78198 [2013d3e2_0.transpose.rot90.rot90.rot90.permute2975813460.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:34<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:0.98849|1.03748 [2013d3e2_0.transpose.rot90.rot90.rot90.permute2975813460.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:34<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.70092|1.70438 [2013d3e2_0.permute9674235801.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:39<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.71453|1.71799 [2013d3e2_0.permute9674235801.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:39<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 22 bad_xy_size:0.60810|1.75296 [2013d3e2_0.permute9674235801.ex10.out2]\n2.  62%|██████▎   | 5/8 [02:39<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.04060|0.64812 [2013d3e2_0.transpose.permute8529017463.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:44<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 32 bad_xy_size:0.05598|1.43196 [2013d3e2_0.transpose.permute8529017463.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:44<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.19386|0.19397 [2013d3e2_0.rot90.permute4835026917.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:44<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:0.20937|0.20942 [2013d3e2_0.transpose.rot90.permute3861504297.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:45<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:0.95247|0.95290 [2013d3e2_0.rot90.rot90.permute4032987651.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:47<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.42178|1.42925 [2013d3e2_0.transpose.rot90.rot90.permute0253947186.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:50<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.69311|1.69389 [2013d3e2_0.transpose.rot90.rot90.permute0253947186.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:50<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.38562|0.38574 [2013d3e2_0.rot90.rot90.rot90.permute1607852934.ex01.out0]\n2.  62%|██████▎   | 5/8 [02:52<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.53553|1.53587 [2013d3e2_0.rot90.rot90.rot90.permute1607852934.ex01.out1]\n2.  62%|██████▎   | 5/8 [02:52<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 ALL_CORRECT:0.86043|0.86055 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out0]\n2.  62%|██████▎   | 5/8 [02:55<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 14 bad_content:1.04240|1.53143 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out1]\n2.  62%|██████▎   | 5/8 [02:55<01:31, 30.63s/it]\n2.  acc:   5/  6=83.3% (2-guess),   6/  6=99.9% (any); tok: 423+ 14> 22 bad_xy_size:0.76536|1.73429 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out2]\n2.  62%|██████▎   | 5/8 [02:55<01:31, 30.63s/it]\n2.  75%|███████▌  | 6/8 [02:55<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00007|0.00007 [28bf18c6_0.permute0526374189.ex201.out0]\n2.  75%|███████▌  | 6/8 [02:58<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00001|0.00002 [28bf18c6_0.transpose.permute3861705429.ex201.out0]\n2.  75%|███████▌  | 6/8 [02:59<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00001|0.00019 [28bf18c6_0.rot90.permute9240631857.ex012.out0]\n2.  75%|███████▌  | 6/8 [02:59<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00002|0.00002 [28bf18c6_0.transpose.rot90.permute3469825107.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:00<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00004|0.00005 [28bf18c6_0.rot90.rot90.permute6720348519.ex201.out0]\n2.  75%|███████▌  | 6/8 [03:01<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00003|0.00004 [28bf18c6_0.transpose.rot90.rot90.permute8467153290.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:02<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00002|0.00010 [28bf18c6_0.rot90.rot90.rot90.permute9752643810.ex012.out0]\n2.  75%|███████▌  | 6/8 [03:02<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00002|0.00009 [28bf18c6_0.transpose.rot90.rot90.rot90.permute2018356497.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:03<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00004|0.00004 [28bf18c6_0.permute3172605849.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:04<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00000|0.00001 [28bf18c6_0.transpose.permute4890675321.ex012.out0]\n2.  75%|███████▌  | 6/8 [03:05<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00001|0.00004 [28bf18c6_0.rot90.permute9534721086.ex210.out0]\n2.  75%|███████▌  | 6/8 [03:05<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00001|0.00001 [28bf18c6_0.transpose.rot90.permute9538401672.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:06<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00002|0.00002 [28bf18c6_0.rot90.rot90.permute6079328154.ex120.out0]\n2.  75%|███████▌  | 6/8 [03:07<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00010|0.00012 [28bf18c6_0.transpose.rot90.rot90.permute8572460391.ex012.out0]\n2.  75%|███████▌  | 6/8 [03:07<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 436+ 26> 26 ALL_CORRECT:0.00003|0.00006 [28bf18c6_0.rot90.rot90.rot90.permute2714038596.ex102.out0]\n2.  75%|███████▌  | 6/8 [03:08<01:02, 31.29s/it]\n2.  acc:   6/  7=85.7% (2-guess),   7/  7=99.9% (any); tok: 427+ 23> 23 ALL_CORRECT:0.00003|0.00004 [28bf18c6_0.transpose.rot90.rot90.rot90.permute9024876153.ex102.out0]\n2.  75%|███████▌  | 6/8 [03:09<01:02, 31.29s/it]\n2.  88%|████████▊ | 7/8 [03:09<00:25, 25.56s/it]\n2.  acc:   6/  8=75.0% (2-guess),   7/  8=87.5% (any); tok: 454+  8>  8 bad_content:0.55913|0.55915 [1fad071e_0.permute4813052976.ex102.out0]\n2.  88%|████████▊ | 7/8 [03:11<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.43679|1.43681 [1fad071e_0.permute4813052976.ex102.out1]\n2.  88%|████████▊ | 7/8 [03:11<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.72686|0.72696 [1fad071e_0.transpose.permute7296518430.ex120.out0]\n2.  88%|████████▊ | 7/8 [03:12<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:1.26847|1.26850 [1fad071e_0.transpose.permute7296518430.ex120.out1]\n2.  88%|████████▊ | 7/8 [03:12<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:1.52374|1.52384 [1fad071e_0.transpose.permute7296518430.ex120.out2]\n2.  88%|████████▊ | 7/8 [03:12<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.72827|0.72829 [1fad071e_0.rot90.permute3104958627.ex120.out0]\n2.  88%|████████▊ | 7/8 [03:14<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:1.18835|1.18838 [1fad071e_0.rot90.permute3104958627.ex120.out1]\n2.  88%|████████▊ | 7/8 [03:14<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.64508|0.64511 [1fad071e_0.transpose.rot90.permute2639504178.ex201.out0]\n2.  88%|████████▊ | 7/8 [03:15<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.28310|1.28313 [1fad071e_0.transpose.rot90.permute2639504178.ex201.out1]\n2.  88%|████████▊ | 7/8 [03:15<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.91929|0.91932 [1fad071e_0.rot90.rot90.permute3012547968.ex201.out0]\n2.  88%|████████▊ | 7/8 [03:16<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.28885|1.28890 [1fad071e_0.rot90.rot90.permute3012547968.ex201.out1]\n2.  88%|████████▊ | 7/8 [03:16<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.53244|0.53246 [1fad071e_0.transpose.rot90.rot90.permute6738420519.ex201.out0]\n2.  88%|████████▊ | 7/8 [03:18<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:1.69352|1.69356 [1fad071e_0.transpose.rot90.rot90.permute6738420519.ex201.out1]\n2.  88%|████████▊ | 7/8 [03:18<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:0.84215|0.84219 [1fad071e_0.rot90.rot90.rot90.permute1482360957.ex210.out0]\n2.  88%|████████▊ | 7/8 [03:19<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.94689|0.94697 [1fad071e_0.rot90.rot90.rot90.permute1482360957.ex210.out1]\n2.  88%|████████▊ | 7/8 [03:19<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.83381|0.83383 [1fad071e_0.transpose.rot90.rot90.rot90.permute6452093178.ex210.out0]\n2.  88%|████████▊ | 7/8 [03:20<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.33622|1.33627 [1fad071e_0.transpose.rot90.rot90.rot90.permute6452093178.ex210.out1]\n2.  88%|████████▊ | 7/8 [03:20<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.46446|0.46449 [1fad071e_0.permute6890731254.ex210.out0]\n2.  88%|████████▊ | 7/8 [03:21<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.69848|1.69850 [1fad071e_0.permute6890731254.ex210.out1]\n2.  88%|████████▊ | 7/8 [03:21<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.84422|0.84435 [1fad071e_0.transpose.permute1769528430.ex120.out0]\n2.  88%|████████▊ | 7/8 [03:22<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.88329|0.88341 [1fad071e_0.transpose.permute1769528430.ex120.out1]\n2.  88%|████████▊ | 7/8 [03:22<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.62134|0.62136 [1fad071e_0.rot90.permute1680247395.ex102.out0]\n2.  88%|████████▊ | 7/8 [03:24<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:1.29496|1.29500 [1fad071e_0.rot90.permute1680247395.ex102.out1]\n2.  88%|████████▊ | 7/8 [03:24<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.66265|0.66269 [1fad071e_0.transpose.rot90.permute7239864105.ex021.out0]\n2.  88%|████████▊ | 7/8 [03:25<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.34114|1.34117 [1fad071e_0.transpose.rot90.permute7239864105.ex021.out1]\n2.  88%|████████▊ | 7/8 [03:25<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.96454|0.96457 [1fad071e_0.rot90.rot90.permute3452817690.ex102.out0]\n2.  88%|████████▊ | 7/8 [03:26<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.10584|1.10591 [1fad071e_0.rot90.rot90.permute3452817690.ex102.out1]\n2.  88%|████████▊ | 7/8 [03:26<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.83105|0.83107 [1fad071e_0.transpose.rot90.rot90.permute7154368092.ex210.out0]\n2.  88%|████████▊ | 7/8 [03:28<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:1.25647|1.25651 [1fad071e_0.transpose.rot90.rot90.permute7154368092.ex210.out1]\n2.  88%|████████▊ | 7/8 [03:28<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 ALL_CORRECT:0.87763|0.87767 [1fad071e_0.rot90.rot90.rot90.permute5079632841.ex102.out0]\n2.  88%|████████▊ | 7/8 [03:29<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 466+ 12> 12 bad_content:0.99798|0.99809 [1fad071e_0.rot90.rot90.rot90.permute5079632841.ex102.out1]\n2.  88%|████████▊ | 7/8 [03:29<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 bad_content:0.87997|0.88000 [1fad071e_0.transpose.rot90.rot90.rot90.permute8734520691.ex201.out0]\n2.  88%|████████▊ | 7/8 [03:30<00:25, 25.56s/it]\n2.  acc:   7/  8=87.5% (2-guess),   8/  8=99.9% (any); tok: 454+  8>  8 ALL_CORRECT:1.18016|1.18020 [1fad071e_0.transpose.rot90.rot90.rot90.permute8734520691.ex201.out1]\n2.  88%|████████▊ | 7/8 [03:30<00:25, 25.56s/it]\n2. 100%|██████████| 8/8 [03:30<00:00, 24.20s/it]\n2. 100%|██████████| 8/8 [03:30<00:00, 26.34s/it]\n2. *** Completed inference run.\n2. calculate augmented scores:   0%|          | 0/8 [00:00<?, ?it/s]\n2. calculate augmented scores:  12%|█▎        | 1/8 [00:03<00:27,  3.96s/it]\n2. calculate augmented scores:  25%|██▌       | 2/8 [00:32<01:50, 18.43s/it]\n2. calculate augmented scores:  38%|███▊      | 3/8 [00:42<01:12, 14.53s/it]\n2. calculate augmented scores:  50%|█████     | 4/8 [01:05<01:12, 18.07s/it]\n2. calculate augmented scores:  62%|██████▎   | 5/8 [01:11<00:40, 13.66s/it]\n2. calculate augmented scores:  75%|███████▌  | 6/8 [02:09<00:57, 28.55s/it]\n2. calculate augmented scores:  88%|████████▊ | 7/8 [02:14<00:21, 21.11s/it]\n2. calculate augmented scores: 100%|██████████| 8/8 [02:32<00:00, 19.97s/it]\n2. calculate augmented scores: 100%|██████████| 8/8 [02:32<00:00, 19.06s/it]\n2. *** GPU: Tesla T4, used 5.28 / 14.7 GB.\n*** Subprocesses exit codes: [0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# write submission\nfrom common_stuff import *\nwith RemapCudaOOM():\n    model, formatter, dataset = None, MyFormatter(), None\n    decoder = Decoder(formatter, arc_test_set.split_multi_replies(), n_guesses=2, frac_score=True).from_store(infer_params['store'])\n    if use_aug_score or arc_test_set.is_fake: decoder.calc_augmented_scores(model=model, store=score_temp_storage, **aug_score_params)\n    submission = arc_test_set.get_submission(decoder.run_selection_algo(submission_select_algo))\n    with open('submission.json', 'w') as f: json.dump(submission, f)\n    if arc_test_set.is_fake:\n        decoder.benchmark_selection_algos(selection_algorithms)\n        with open('submission.json') as f: reload_submission = json.load(f)\n        print('*** Reload score:', arc_test_set.validate_submission(reload_submission))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T20:14:14.042309Z","iopub.execute_input":"2025-06-27T20:14:14.043493Z","iopub.status.idle":"2025-06-27T20:14:14.484043Z","shell.execute_reply.started":"2025-06-27T20:14:14.043451Z","shell.execute_reply":"2025-06-27T20:14:14.482869Z"}},"outputs":[{"name":"stdout","text":" acc:   1.0/  1=99.9% (2-guess),   1.0/  1=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.permute4156892370.ex120.out0]\n acc:   2.0/  2=99.9% (2-guess),   2.0/  2=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00000|0.00001 [28bf18c6_0.transpose.permute4890675321.ex012.out0]\n acc:   3.0/  3=99.9% (2-guess),   3.0/  3=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00037|0.00037 [3c9b0459_0.rot90.rot90.permute7054189263.ex0231.out0]\n acc:   4.0/  4=99.9% (2-guess),   4.0/  4=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.07056|0.07058 [25ff71a9_0.transpose.rot90.rot90.rot90.permute6370481259.ex2103.out0]\n acc:   5.0/  5=99.9% (2-guess),   5.0/  5=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.86043|0.86055 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out0]\n acc:   5.0/  5=99.9% (2-guess),   5.0/  5=99.9% (any); tok:   ?+  ?> 14 bad_content:1.04240|1.53143 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out1]\n acc:   5.0/  5=99.9% (2-guess),   5.0/  5=99.9% (any); tok:   ?+  ?> 22 bad_xy_size:0.76536|1.73429 [2013d3e2_0.transpose.rot90.rot90.rot90.permute5630492718.ex10.out2]\n acc:   6.0/  6=99.9% (2-guess),   6.0/  6=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.71179|0.71188 [27a28665_0.rot90.permute3861504297.ex4102365.out0]\n acc:   6.0/  6=99.9% (2-guess),   6.0/  6=99.9% (any); tok:   ?+  ?>  4 bad_content:1.53210|1.53219 [27a28665_0.rot90.permute3861504297.ex4102365.out1]\n acc:   6.0/  6=99.9% (2-guess),   6.0/  6=99.9% (any); tok:   ?+  ?>  4 bad_content:1.72351|1.72360 [27a28665_0.rot90.permute3861504297.ex4102365.out2]\n acc:   5.3/  6=88.9% (2-guess),   5.3/  6=88.9% (any); tok:   ?+  ?>  4 bad_content:0.90651|0.90659 [27a28665_2.transpose.permute5963817024.ex2415306.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.72292|1.72384 [27a28665_2.transpose.permute5963817024.ex2415306.out1]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.78193|0.78198 [2013d3e2_0.transpose.rot90.rot90.rot90.permute2975813460.ex10.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?> 14 bad_content:0.98849|1.03748 [2013d3e2_0.transpose.rot90.rot90.rot90.permute2975813460.ex10.out1]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00005|0.00005 [0520fde7_0.transpose.rot90.permute6597130824.ex012.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 bad_content:0.74839|0.74851 [27a28665_2.transpose.rot90.rot90.permute3215690874.ex3412506.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.48276|1.48316 [27a28665_2.transpose.rot90.rot90.permute3215690874.ex3412506.out1]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00024|0.00024 [0520fde7_0.rot90.permute1504397682.ex120.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 bad_content:0.61480|0.61486 [27a28665_0.permute2348716095.ex4361250.out0]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 bad_content:1.29839|1.29846 [27a28665_0.permute2348716095.ex4361250.out1]\n acc:   5.7/  6=94.4% (2-guess),   5.7/  6=94.4% (any); tok:   ?+  ?>  4 bad_content:1.06636|1.06649 [27a28665_1.rot90.rot90.rot90.permute1927360458.ex3506142.out0]\n acc:   6.7/  7=95.2% (2-guess),   6.7/  7=95.2% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00021|0.00021 [3af2c5a8_0.transpose.rot90.rot90.rot90.permute5264931807.ex012.out0]\n acc:   6.7/  8=83.3% (2-guess),   6.7/  8=83.3% (any); tok:   ?+  ?> 32 bad_content:0.03398|0.03398 [1e0a9b12_0.transpose.rot90.permute9021654837.ex120.out0]\n acc:   7.7/  9=85.2% (2-guess),   7.7/  9=85.2% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00717|0.00718 [25d8a9c8_0.rot90.rot90.permute3947086521.ex0123.out0]\n acc:   8.7/ 10=86.7% (2-guess),   8.7/ 10=86.7% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.36757|0.36759 [3ac3eb23_0.rot90.rot90.permute4236781950.ex10.out0]\n acc:   8.7/ 10=86.7% (2-guess),   8.7/ 10=86.7% (any); tok:   ?+  ?> 80 bad_content:1.38630|1.38636 [3ac3eb23_0.rot90.rot90.permute4236781950.ex10.out1]\n acc:   8.7/ 10=86.7% (2-guess),   8.7/ 10=86.7% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02709|0.02711 [25ff71a9_1.rot90.rot90.permute3690847152.ex3102.out0]\n acc:   8.7/ 10=86.7% (2-guess),   8.7/ 10=86.7% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00022|0.00022 [3c9b0459_0.transpose.rot90.permute2953841607.ex1320.out0]\n acc:   9.7/ 11=87.9% (2-guess),   9.7/ 11=87.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00012|0.00012 [29c11459_0.transpose.rot90.rot90.rot90.permute5947062381.ex01.out0]\n acc:   9.7/ 11=87.9% (2-guess),   9.7/ 11=87.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.09541|0.09549 [25ff71a9_1.transpose.rot90.rot90.rot90.permute7450123869.ex2103.out0]\n acc:   9.7/ 11=87.9% (2-guess),   9.7/ 11=87.9% (any); tok:   ?+  ?>  4 bad_content:0.25224|0.25226 [27a28665_0.transpose.rot90.permute1745239680.ex5034621.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 12 ALL_CORRECT:0.84215|0.84219 [1fad071e_0.rot90.rot90.rot90.permute1482360957.ex210.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 12 bad_content:0.94689|0.94697 [1fad071e_0.rot90.rot90.rot90.permute1482360957.ex210.out1]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02308|0.02309 [25ff71a9_0.rot90.permute2796081354.ex3201.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  4 bad_content:1.73291|1.73331 [27a28665_1.permute4315762098.ex3405126.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 32 bad_content:0.60257|0.60258 [1e0a9b12_0.permute6870592413.ex210.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 32 bad_content:1.26334|1.26336 [1e0a9b12_0.permute6870592413.ex210.out1]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00005|0.00006 [3c9b0459_0.rot90.rot90.permute3270985461.ex0213.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  4 bad_content:1.08436|1.08459 [27a28665_1.transpose.rot90.rot90.permute2641509873.ex2360145.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  4 bad_content:1.45546|1.45570 [27a28665_1.transpose.rot90.rot90.permute2641509873.ex2360145.out1]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  8 bad_content:0.91929|0.91932 [1fad071e_0.rot90.rot90.permute3012547968.ex201.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.28885|1.28890 [1fad071e_0.rot90.rot90.permute3012547968.ex201.out1]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00000|0.00000 [0520fde7_0.transpose.rot90.permute1384970526.ex012.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00458|0.00458 [3c9b0459_0.transpose.rot90.rot90.rot90.permute3920517486.ex0312.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01124|0.01125 [25ff71a9_0.rot90.permute8097261354.ex2130.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 bad_content:1.30223|1.33578 [2013d3e2_0.transpose.rot90.rot90.permute1570324869.ex01.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  4 bad_content:0.65056|0.65072 [27a28665_1.transpose.permute2103984576.ex3560124.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  8 bad_content:0.55913|0.55915 [1fad071e_0.permute4813052976.ex102.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.43679|1.43681 [1fad071e_0.permute4813052976.ex102.out1]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 14 bad_content:0.20937|0.20942 [2013d3e2_0.transpose.rot90.permute3861504297.ex10.out0]\n acc:  10.7/ 12=88.9% (2-guess),  10.7/ 12=88.9% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.00004|0.00004 [3ac3eb23_0.transpose.rot90.rot90.rot90.permute9175426038.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  11.7/ 13=89.7% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.08725|0.08726 [0d3d703e_0.rot90.permute1384970526.ex1320.out0]\n acc:  11.7/ 13=89.7% (2-guess),  11.7/ 13=89.7% (any); tok:   ?+  ?> 12 bad_content:0.72686|0.72696 [1fad071e_0.transpose.permute7296518430.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  11.7/ 13=89.7% (any); tok:   ?+  ?> 12 ALL_CORRECT:1.26847|1.26850 [1fad071e_0.transpose.permute7296518430.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  11.7/ 13=89.7% (any); tok:   ?+  ?> 12 bad_content:1.52374|1.52384 [1fad071e_0.transpose.permute7296518430.ex120.out2]\n acc:  11.7/ 13=89.7% (2-guess),  11.7/ 13=89.7% (any); tok:   ?+  ?>  4 bad_content:0.68692|0.68709 [27a28665_1.transpose.rot90.rot90.rot90.permute5304781296.ex5231604.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.12442|1.12475 [27a28665_1.transpose.rot90.rot90.rot90.permute5304781296.ex5231604.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.10593|0.10594 [0d3d703e_0.transpose.rot90.rot90.permute7041952368.ex2310.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:0.07333|0.07334 [27a28665_0.transpose.rot90.rot90.rot90.permute3694028715.ex2053164.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00010|0.00012 [28bf18c6_0.transpose.rot90.rot90.permute8572460391.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.transpose.rot90.rot90.rot90.permute0365427918.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.29106|1.29114 [27a28665_1.transpose.permute8694503217.ex0652431.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.68168|1.68178 [27a28665_1.transpose.permute8694503217.ex0652431.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.74418|1.74442 [27a28665_1.transpose.permute8694503217.ex0652431.out2]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:0.16465|0.16477 [25d8a9c8_0.rot90.rot90.rot90.permute8521497603.ex1203.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00143|0.00143 [3af2c5a8_0.rot90.rot90.permute0928167354.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 ALL_CORRECT:0.87763|0.87767 [1fad071e_0.rot90.rot90.rot90.permute5079632841.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 bad_content:0.99798|0.99809 [1fad071e_0.rot90.rot90.rot90.permute5079632841.ex102.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.39904|0.39905 [3ac3eb23_0.rot90.rot90.rot90.permute2107946853.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 86 bad_content:1.61014|1.61015 [3ac3eb23_0.rot90.rot90.rot90.permute2107946853.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 bad_content:0.96454|0.96457 [1fad071e_0.rot90.rot90.permute3452817690.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.10584|1.10591 [1fad071e_0.rot90.rot90.permute3452817690.ex102.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.59674|1.59681 [0d3d703e_0.transpose.rot90.permute8672310495.ex3012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00131|0.00131 [0520fde7_0.rot90.rot90.rot90.permute6498012573.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:1.35312|1.35318 [0d3d703e_0.transpose.rot90.permute4032987651.ex0321.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00012|0.00012 [29c11459_0.transpose.rot90.rot90.rot90.permute4068123597.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00180|0.00181 [25d8a9c8_0.transpose.rot90.permute6079328154.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:0.56978|0.56991 [27a28665_1.rot90.permute9538401672.ex3521460.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00002|0.00002 [0520fde7_0.permute2874513906.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.48057|0.48059 [3ac3eb23_0.transpose.rot90.permute5672940813.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 80 bad_content:1.56074|1.56079 [3ac3eb23_0.transpose.rot90.permute5672940813.ex01.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00321|0.00321 [25ff71a9_0.transpose.permute7296518430.ex3120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.68697|0.68702 [27a28665_0.permute8257319046.ex0631452.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:0.96822|0.96827 [27a28665_0.permute8257319046.ex0631452.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00071|0.00072 [3c9b0459_0.transpose.rot90.rot90.permute3942051768.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:0.25718|0.25930 [25d8a9c8_0.transpose.rot90.rot90.permute6021947358.ex0132.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00003|0.00006 [28bf18c6_0.rot90.rot90.rot90.permute2714038596.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00061|0.00062 [3ac3eb23_0.transpose.permute8594670321.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 bad_content:0.46446|0.46449 [1fad071e_0.permute6890731254.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.69848|1.69850 [1fad071e_0.permute6890731254.ex210.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.04126|0.04126 [0d3d703e_0.rot90.rot90.rot90.permute9208314675.ex2031.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.03907|0.03907 [0d3d703e_0.transpose.permute9132548760.ex2013.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00036|0.00036 [29c11459_0.transpose.rot90.permute8940537621.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.09590|0.09591 [0d3d703e_0.rot90.permute5764021983.ex0132.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.25289|1.25375 [27a28665_2.transpose.rot90.permute3618725490.ex2306415.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.30912|0.30915 [25ff71a9_1.permute1762803459.ex1032.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:1.38424|1.38428 [25ff71a9_1.permute1762803459.ex1032.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.permute8150729436.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.03766|0.03767 [25ff71a9_0.rot90.rot90.permute5480123967.ex1302.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00004|0.00004 [3ac3eb23_0.rot90.permute7368249501.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00103|0.00104 [25ff71a9_0.transpose.rot90.rot90.permute8046317529.ex1032.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.19386|0.19397 [2013d3e2_0.rot90.permute4835026917.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00037|0.00037 [3af2c5a8_0.transpose.rot90.rot90.rot90.permute7236948015.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 bad_content:0.83105|0.83107 [1fad071e_0.transpose.rot90.rot90.permute7154368092.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 ALL_CORRECT:1.25647|1.25651 [1fad071e_0.transpose.rot90.rot90.permute7154368092.ex210.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00020|0.00021 [3ac3eb23_0.transpose.permute2187306594.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:0.10927|0.10929 [27a28665_0.transpose.rot90.rot90.permute5194638720.ex3645012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 bad_content:0.66265|0.66269 [1fad071e_0.transpose.rot90.permute7239864105.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.34114|1.34117 [1fad071e_0.transpose.rot90.permute7239864105.ex021.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:0.14567|0.14574 [25d8a9c8_0.transpose.permute3861705429.ex1302.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:0.62281|0.62290 [27a28665_0.transpose.permute6314970528.ex6241350.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.50172|1.50180 [27a28665_0.transpose.permute6314970528.ex6241350.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.69703|1.69714 [27a28665_0.transpose.permute6314970528.ex6241350.out2]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.56617|0.56622 [27a28665_0.rot90.rot90.permute4209781563.ex5423610.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.59742|1.59750 [27a28665_0.rot90.rot90.permute4209781563.ex5423610.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.19262|1.19282 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.61449|1.61471 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  4 bad_content:1.69652|1.69673 [27a28665_1.transpose.rot90.rot90.permute4160723958.ex5360421.out2]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.29242|0.29247 [25d8a9c8_0.transpose.rot90.rot90.rot90.permute8421630795.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 bad_content:0.72827|0.72829 [1fad071e_0.rot90.permute3104958627.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 12 ALL_CORRECT:1.18835|1.18838 [1fad071e_0.rot90.permute3104958627.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 bad_content:0.56419|0.62906 [2013d3e2_0.permute8257319046.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.41621|1.74301 [2013d3e2_0.permute8257319046.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 bad_content:0.87997|0.88000 [1fad071e_0.transpose.rot90.rot90.rot90.permute8734520691.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  12.0/ 13=92.3% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.18016|1.18020 [1fad071e_0.transpose.rot90.rot90.rot90.permute8734520691.ex201.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.39840|0.39843 [1e0a9b12_0.rot90.rot90.permute8473016925.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:1.39780|1.39782 [1e0a9b12_0.rot90.rot90.permute8473016925.ex012.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.31054|0.31058 [3ac3eb23_0.transpose.rot90.permute4078361529.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 bad_content:1.43413|1.43418 [3ac3eb23_0.transpose.rot90.permute4078361529.ex01.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00004|0.00004 [28bf18c6_0.permute3172605849.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00001|0.00002 [28bf18c6_0.transpose.permute3861705429.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.47919|0.47920 [1e0a9b12_0.transpose.permute5910762348.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:0.98098|0.98098 [1e0a9b12_0.transpose.permute5910762348.ex210.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00004|0.00005 [28bf18c6_0.rot90.rot90.permute6720348519.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00007|0.00007 [29c11459_0.permute0673298145.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00041|0.00041 [3af2c5a8_0.transpose.rot90.permute7352408961.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.05421|0.06684 [2013d3e2_0.transpose.permute9132548760.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.transpose.rot90.rot90.permute8604172935.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00135|0.00135 [25d8a9c8_0.rot90.rot90.permute0294781653.ex1203.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00006|0.00006 [3c9b0459_0.transpose.rot90.rot90.permute8407362159.ex3210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.03857|0.03857 [25ff71a9_0.rot90.rot90.rot90.permute2089157364.ex3210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.05252|0.05252 [29c11459_0.transpose.permute4598260713.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.permute1762803459.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.07205|0.07207 [25ff71a9_0.transpose.rot90.rot90.rot90.permute4912085376.ex1023.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.36387|0.36389 [27a28665_0.rot90.permute0948263157.ex6421503.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.43808|1.43812 [27a28665_0.rot90.permute0948263157.ex6421503.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.00046|0.00046 [1e0a9b12_0.rot90.permute2103984576.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.00659|0.00665 [3af2c5a8_0.rot90.rot90.rot90.permute5862037914.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.98935|0.98987 [27a28665_2.permute4813052976.ex1526034.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.36345|0.36351 [2013d3e2_0.transpose.rot90.permute0579623418.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.45720|1.45725 [2013d3e2_0.transpose.rot90.permute0579623418.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.05802|0.05803 [1e0a9b12_0.transpose.permute0857149623.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.37615|1.37651 [27a28665_1.rot90.permute3461827905.ex0364215.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.04813|0.04814 [25ff71a9_1.rot90.rot90.rot90.permute8713495602.ex0213.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00001|0.00004 [28bf18c6_0.rot90.permute9534721086.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.61446|0.61447 [1e0a9b12_0.rot90.rot90.permute0594736812.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:0.78697|0.78698 [1e0a9b12_0.rot90.rot90.permute0594736812.ex021.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.23239|0.23248 [27a28665_1.transpose.rot90.permute5490731286.ex5302164.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00312|0.00313 [25ff71a9_1.transpose.permute2896147503.ex1302.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.02077|0.02077 [29c11459_0.rot90.permute3710429658.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.00049|0.00049 [3af2c5a8_0.rot90.permute3216708459.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.66239|0.66243 [25ff71a9_1.permute2054891763.ex0321.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.95952|0.95956 [25ff71a9_1.permute2054891763.ex0321.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00632|0.00633 [25ff71a9_0.transpose.rot90.rot90.permute8045261937.ex1203.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00039|0.00039 [25d8a9c8_0.transpose.rot90.rot90.rot90.permute6457102398.ex1203.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00001|0.00001 [3ac3eb23_0.rot90.permute4165297308.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00011|0.00011 [3c9b0459_0.rot90.permute9184520673.ex1203.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.27862|0.27864 [25d8a9c8_0.transpose.permute2561379084.ex3021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.48175|1.48176 [25d8a9c8_0.transpose.permute2561379084.ex3021.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.00005|0.00005 [3ac3eb23_0.transpose.rot90.rot90.permute1308647925.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:0.58250|0.58252 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute4239705681.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:1.53615|1.53617 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute4239705681.ex201.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00020|0.00021 [3c9b0459_0.rot90.rot90.rot90.permute3496817025.ex0123.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00002|0.00002 [28bf18c6_0.transpose.rot90.permute3469825107.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.61158|0.61163 [27a28665_0.rot90.rot90.permute0476951382.ex0625134.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.22877|1.22882 [27a28665_0.rot90.rot90.permute0476951382.ex0625134.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01023|0.01025 [25d8a9c8_0.permute6934175082.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.04605|0.04606 [29c11459_0.rot90.rot90.rot90.permute5896340271.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00008|0.00008 [29c11459_0.transpose.rot90.permute0341257869.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00003|0.00003 [3c9b0459_0.transpose.permute0742586913.ex3021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  8 bad_content:0.64508|0.64511 [1fad071e_0.transpose.rot90.permute2639504178.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.28310|1.28313 [1fad071e_0.transpose.rot90.permute2639504178.ex201.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.58306|0.58312 [25ff71a9_1.transpose.rot90.rot90.rot90.permute1680392475.ex2310.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.96340|0.96461 [25ff71a9_1.transpose.rot90.rot90.rot90.permute1680392475.ex2310.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00070|0.00070 [0520fde7_0.rot90.permute6314970528.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.04747|0.04749 [25d8a9c8_0.transpose.rot90.permute7981642503.ex0321.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 bad_content:0.24809|0.24811 [3af2c5a8_0.transpose.rot90.rot90.permute7513206948.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:1.65425|1.65429 [3af2c5a8_0.transpose.rot90.rot90.permute7513206948.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01221|0.01221 [25ff71a9_1.transpose.rot90.rot90.permute4908735612.ex0132.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.56252|0.56255 [3ac3eb23_0.rot90.rot90.permute5061423978.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 bad_content:0.95651|0.95656 [3ac3eb23_0.rot90.rot90.permute5061423978.ex01.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.38562|0.38574 [2013d3e2_0.rot90.rot90.rot90.permute1607852934.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.53553|1.53587 [2013d3e2_0.rot90.rot90.rot90.permute1607852934.ex01.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.00330|0.00330 [1e0a9b12_0.rot90.rot90.rot90.permute2085176934.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00012|0.00012 [3af2c5a8_0.transpose.rot90.permute2796081354.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02309|0.02309 [0d3d703e_0.rot90.rot90.rot90.permute0312769485.ex2130.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 bad_content:0.53244|0.53246 [1fad071e_0.transpose.rot90.rot90.permute6738420519.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 ALL_CORRECT:1.69352|1.69356 [1fad071e_0.transpose.rot90.rot90.permute6738420519.ex201.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.93326|0.93345 [27a28665_2.permute8705426193.ex0326154.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.11051|0.11053 [25ff71a9_0.rot90.rot90.permute8975420361.ex2103.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00845|0.00846 [25ff71a9_1.transpose.permute4091873652.ex1230.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.rot90.rot90.rot90.permute7289501634.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00003|0.00003 [3c9b0459_0.transpose.permute2096517483.ex1320.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00005|0.00006 [3c9b0459_0.permute1548076329.ex2103.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.66335|1.66352 [27a28665_1.permute0526374189.ex5260431.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.35868|0.35872 [25ff71a9_1.rot90.rot90.rot90.permute6735248910.ex1230.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.transpose.permute5012869347.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.02829|0.02829 [3af2c5a8_0.permute9206853714.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.05700|0.05700 [25ff71a9_0.permute9206853714.ex3012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.42832|0.42836 [27a28665_0.transpose.permute5629138470.ex4136025.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.74082|1.74086 [27a28665_0.transpose.permute5629138470.ex4136025.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00365|0.00365 [3af2c5a8_0.permute3857410629.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.32910|1.32925 [27a28665_2.transpose.rot90.permute3752061489.ex4305261.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.27832|0.27837 [27a28665_0.transpose.rot90.permute2576908143.ex0431265.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.60322|0.60343 [2013d3e2_0.rot90.rot90.permute9517802463.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.00255|0.00255 [3af2c5a8_0.transpose.permute9182036754.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:0.02266|0.02266 [1e0a9b12_0.transpose.rot90.permute8152047936.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 bad_content:0.62134|0.62136 [1fad071e_0.rot90.permute1680247395.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 ALL_CORRECT:1.29496|1.29500 [1fad071e_0.rot90.permute1680247395.ex102.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.23786|1.23803 [27a28665_2.rot90.permute7239864105.ex1530462.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.45661|1.45684 [27a28665_2.rot90.permute7239864105.ex1530462.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.55817|1.55836 [27a28665_2.rot90.permute7239864105.ex1530462.out2]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.00059|0.00059 [3af2c5a8_0.rot90.permute4382705916.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00112|0.00112 [25ff71a9_0.transpose.rot90.permute9238567041.ex0321.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00002|0.00002 [28bf18c6_0.rot90.rot90.permute6079328154.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00985|0.00985 [25ff71a9_0.rot90.rot90.rot90.permute1568927430.ex2310.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  8 bad_content:0.83381|0.83383 [1fad071e_0.transpose.rot90.rot90.rot90.permute6452093178.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  8 ALL_CORRECT:1.33622|1.33627 [1fad071e_0.transpose.rot90.rot90.rot90.permute6452093178.ex210.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00002|0.00010 [28bf18c6_0.rot90.rot90.rot90.permute9752643810.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00000|0.00000 [0520fde7_0.transpose.rot90.rot90.permute3128906475.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00006|0.00006 [3c9b0459_0.rot90.permute0341257869.ex2130.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00001|0.00019 [28bf18c6_0.rot90.permute9240631857.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.41830|1.41850 [27a28665_1.rot90.rot90.rot90.permute8634120759.ex2463015.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.76986|1.77003 [27a28665_1.rot90.rot90.rot90.permute8634120759.ex2463015.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 56 ALL_CORRECT:0.00071|0.00071 [3af2c5a8_0.rot90.rot90.permute6028439751.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00241|0.00242 [0520fde7_0.transpose.rot90.rot90.rot90.permute3290157684.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 80 ALL_CORRECT:0.00002|0.00002 [3ac3eb23_0.permute4837605912.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.00568|0.00568 [29c11459_0.transpose.rot90.rot90.permute8061953274.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:1.49243|1.49244 [1e0a9b12_0.permute0185347962.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:1.49608|1.49611 [1e0a9b12_0.permute0185347962.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:1.63314|1.63316 [1e0a9b12_0.permute0185347962.ex120.out2]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.95247|0.95290 [2013d3e2_0.rot90.rot90.permute4032987651.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.50290|0.50291 [3af2c5a8_0.transpose.rot90.rot90.permute2376841590.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 bad_content:0.94418|0.94418 [3af2c5a8_0.transpose.rot90.rot90.permute2376841590.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.18968|0.18987 [2013d3e2_0.rot90.rot90.rot90.permute3219567804.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00001|0.00001 [0520fde7_0.rot90.rot90.permute8217503946.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00003|0.00004 [28bf18c6_0.transpose.rot90.rot90.rot90.permute9024876153.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 86 ALL_CORRECT:0.41632|0.41634 [3ac3eb23_0.rot90.rot90.rot90.permute0285196734.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00008|0.00008 [0520fde7_0.transpose.rot90.rot90.permute1679452803.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.00061|0.00061 [1e0a9b12_0.transpose.rot90.rot90.permute8317290645.ex102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.04060|0.64812 [2013d3e2_0.transpose.permute8529017463.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_xy_size:0.05598|1.43196 [2013d3e2_0.transpose.permute8529017463.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.00417|0.00417 [1e0a9b12_0.transpose.rot90.rot90.permute2734605819.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00185|0.00186 [3c9b0459_0.permute3245179608.ex0312.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.04602|0.04605 [25ff71a9_1.rot90.permute2631987045.ex0123.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.05097|0.05099 [25ff71a9_1.transpose.rot90.permute2683945017.ex2310.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01492|0.01493 [25ff71a9_0.transpose.permute3120459678.ex2103.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.03246|0.03246 [1e0a9b12_0.rot90.rot90.rot90.permute3275198046.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.68573|1.68591 [27a28665_2.rot90.rot90.permute0591328467.ex0125364.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00045|0.00046 [3c9b0459_0.transpose.rot90.permute8096742315.ex3012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.01188|0.01189 [29c11459_0.transpose.permute7243851609.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.70092|1.70438 [2013d3e2_0.permute9674235801.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.71453|1.71799 [2013d3e2_0.permute9674235801.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 22 bad_xy_size:0.60810|1.75296 [2013d3e2_0.permute9674235801.ex10.out2]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:0.97176|0.97179 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute6857219340.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 bad_content:1.37294|1.37297 [1e0a9b12_0.transpose.rot90.rot90.rot90.permute6857219340.ex021.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.08253|0.08254 [29c11459_0.transpose.rot90.rot90.permute1397508426.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.56742|1.56760 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.61039|1.61056 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.76273|1.76291 [27a28665_1.rot90.rot90.permute0357912486.ex5403621.out2]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.22564|0.22588 [25d8a9c8_0.rot90.rot90.rot90.permute9153084627.ex0312.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.68342|0.68343 [0d3d703e_0.transpose.rot90.rot90.permute9146385207.ex0321.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.07405|1.07405 [0d3d703e_0.transpose.rot90.rot90.permute9146385207.ex0321.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01701|0.01702 [25d8a9c8_0.permute0185347962.ex1302.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.03336|0.03336 [3af2c5a8_0.transpose.permute8451396702.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.38987|1.39024 [27a28665_1.rot90.rot90.permute4087162539.ex5326401.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.71409|1.71436 [27a28665_1.rot90.rot90.permute4087162539.ex5326401.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02968|0.02969 [0d3d703e_0.transpose.permute8569347012.ex2130.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.60560|1.60577 [27a28665_1.transpose.rot90.permute2371985460.ex3541260.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.62123|1.62138 [27a28665_1.transpose.rot90.permute2371985460.ex3541260.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.63996|1.64012 [27a28665_2.rot90.rot90.permute6518427093.ex3245601.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.70636|1.70773 [27a28665_2.rot90.rot90.permute6518427093.ex3245601.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00022|0.00022 [29c11459_0.permute1548076329.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.46309|0.46343 [25d8a9c8_0.transpose.rot90.rot90.permute0756982341.ex3012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.72090|1.72124 [25d8a9c8_0.transpose.rot90.rot90.permute0756982341.ex3012.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 32 ALL_CORRECT:0.00111|0.00111 [1e0a9b12_0.rot90.permute7630598412.ex021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 bad_content:0.84422|0.84435 [1fad071e_0.transpose.permute1769528430.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 12 bad_content:0.88329|0.88341 [1fad071e_0.transpose.permute1769528430.ex120.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.01165|0.01166 [25ff71a9_1.rot90.permute4078361529.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.03951|0.03956 [2013d3e2_0.rot90.permute1856342970.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.08861|0.08862 [27a28665_0.rot90.rot90.rot90.permute2385409167.ex5016243.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.36146|0.36173 [25d8a9c8_0.rot90.permute8152047936.ex0231.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.48644|1.48670 [25d8a9c8_0.rot90.permute8152047936.ex0231.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00007|0.00007 [28bf18c6_0.permute0526374189.ex201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00002|0.00009 [28bf18c6_0.transpose.rot90.rot90.rot90.permute2018356497.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.69847|1.69865 [27a28665_2.transpose.rot90.rot90.rot90.permute6894501327.ex3240651.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.75706|1.75722 [27a28665_2.transpose.rot90.rot90.rot90.permute6894501327.ex3240651.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.68593|0.68597 [27a28665_0.transpose.rot90.rot90.permute6019845237.ex2564031.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.78750|0.78753 [27a28665_0.transpose.rot90.rot90.permute6019845237.ex2564031.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.80642|0.80648 [0d3d703e_0.transpose.rot90.rot90.rot90.permute8530497126.ex3210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:0.06418|0.06419 [27a28665_0.transpose.rot90.rot90.rot90.permute5730148926.ex0523164.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 58 ALL_CORRECT:0.00900|0.00900 [3af2c5a8_0.rot90.rot90.rot90.permute0248369571.ex012.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 23 ALL_CORRECT:0.00001|0.00001 [28bf18c6_0.transpose.rot90.permute9538401672.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00373|0.00374 [3c9b0459_0.transpose.rot90.rot90.rot90.permute4201579863.ex3021.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.05802|1.05820 [27a28665_2.rot90.rot90.rot90.permute2893741065.ex5134062.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.76118|0.76122 [25ff71a9_0.permute4620798513.ex0123.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:1.54998|1.55001 [25ff71a9_0.permute4620798513.ex0123.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.75857|1.75905 [27a28665_1.transpose.rot90.rot90.rot90.permute8263471095.ex2136045.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:0.67715|0.68133 [25d8a9c8_0.rot90.permute4872906153.ex0123.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.81386|0.81810 [25d8a9c8_0.rot90.permute4872906153.ex0123.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00002|0.00002 [0520fde7_0.rot90.rot90.permute5274316980.ex210.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02204|0.02204 [25ff71a9_1.transpose.rot90.permute3450192687.ex0231.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:0.70398|0.70405 [27a28665_0.rot90.rot90.rot90.permute8452731960.ex3421506.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 ALL_CORRECT:1.21570|1.21577 [27a28665_0.rot90.rot90.rot90.permute8452731960.ex3421506.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.19480|0.19481 [25ff71a9_1.rot90.rot90.permute9243176058.ex3201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.74156|1.74157 [25ff71a9_1.rot90.rot90.permute9243176058.ex3201.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?>  4 bad_content:1.35299|1.35316 [27a28665_2.transpose.rot90.rot90.permute8273406195.ex2530461.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.02146|0.02147 [29c11459_0.rot90.permute1547328690.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.42178|1.42925 [2013d3e2_0.transpose.rot90.rot90.permute0253947186.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 bad_content:1.69311|1.69389 [2013d3e2_0.transpose.rot90.rot90.permute0253947186.ex10.out1]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00093|0.00093 [29c11459_0.rot90.rot90.permute9251687430.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 26 ALL_CORRECT:0.00003|0.00004 [28bf18c6_0.transpose.rot90.rot90.permute8467153290.ex120.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.02011|0.02011 [25ff71a9_1.transpose.rot90.rot90.permute1045962738.ex3201.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00008|0.00008 [3c9b0459_0.rot90.rot90.rot90.permute9017823645.ex1302.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00632|0.00633 [25ff71a9_0.transpose.rot90.permute3452817690.ex3102.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 62 ALL_CORRECT:0.00117|0.00117 [29c11459_0.rot90.rot90.permute8027346591.ex01.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 68 ALL_CORRECT:0.02810|0.02810 [29c11459_0.rot90.rot90.rot90.permute6794251830.ex10.out0]\n acc:  11.7/ 13=89.7% (2-guess),  13.0/ 13=99.9% (any); tok:   ?+  ?> 14 ALL_CORRECT:0.00599|0.00599 [0520fde7_0.rot90.rot90.rot90.permute0372196854.ex021.out0]\ncalculate augmented scores: 100%|██████████| 16/16 [00:00<00:00, 232.05it/s]\n*** Generating submission for 16 outputs...\n*** Benchmark selection algorithms...\n acc:  11.3/ 13=87.18% ('first_only')\n acc:  11.7/ 13=89.74% ('keep_order')\n acc:  11.7/ 13=89.74% ('keep_order_unique')\n acc:  12.7/ 13=97.44% ('score_all_probsum')\n acc:  12.7/ 13=97.44% ('score_full_probmul_3')\n*** Reload score: 13.166666666666666\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T14:56:09.369730Z","iopub.execute_input":"2025-06-27T14:56:09.369986Z","iopub.status.idle":"2025-06-27T14:56:10.496631Z","shell.execute_reply.started":"2025-06-27T14:56:09.369961Z","shell.execute_reply":"2025-06-27T14:56:10.495296Z"}},"outputs":[{"name":"stdout","text":"Python 3.10.14\n","output_type":"stream"}],"execution_count":1}]}